{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Notes  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**test statistic** = $\\large \\tfrac{ \\text {observed value - hypothesized value}}{\\text{std dev of estimate (aka std error)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. **t-stat** of an estimator (such as of $\\hat\\beta_{1}$) for hypothesis testing = $\\large \\tfrac{\\text{sample coefficient - hypothesized value}}{\\text{std dev of coefficient (aka std error of coefficient)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or **t-stat** of an estimator (such as of $\\hat\\beta_{1}$), from R regression output, (where hypothesized value = 0) = $\\large \\tfrac{\\text{sample coefficient}}{\\text{std dev of coefficient (aka std error of coefficient)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "**p-value** = P(Observed Test Statistic; given $H_0$ is true)  \n",
    "\n",
    "Example, using standard normal distribution:  \n",
    "$z_0$ = our Z test statistic, calculated using formula. The test statistic depenends on the particular type of test. p-value is calculated from the test statistic (use $\\tfrac{\\alpha}{2}$ for two-sided test).  \n",
    "$z_\\alpha$ or $z_\\tfrac{\\alpha}{2}$ = our critical value (from table)  \n",
    "(1-$\\alpha$)% = confidence level   \n",
    "$\\alpha$ = significance level = critical region = area under curve to the left or right of the **critical value** (for left-tailed or right-tailed, respectively) or both (for two-tailed test). See picture below.  \n",
    "p-value = area under curve to the left or right of the **test statistic** (for left-tailed or right-tailed, respectively) or both (for two-tailed test).  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing using z test statistic (standard normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "| | Left-tailed|Two-tailed |Right-tailed |\n",
    " | --- | --- | --- | --- |\n",
    " |Null Hypotyhesis      |$H_0$ = ?   |$H_0$ = ?    |$H_0$ = ?    |\n",
    " |Alternative Hypothesis|$H_1$ < ?   |$H_0$ $\\ne$ ?|$H_1$ > ?    |\n",
    " |Confidence level      |(1-$\\alpha$)%    |(1-$\\alpha$)%|(1-$\\alpha$)%|\n",
    " |Traditional method:<br>Uses **critical value**    |---|---|---|\n",
    " |critical value|P(Z<$z_\\alpha$) = $\\alpha$, find $z_\\alpha$  |P(Z<$z_\\tfrac{\\alpha}{2}$) = $\\tfrac{\\alpha}{2}$, find $z_\\tfrac{\\alpha}{2}$  |P(Z>$z_\\alpha$) = $\\alpha$, find $z_\\alpha$  | \n",
    " |   |qnorm($\\alpha$)|$\\pm$qnorm(1 - $\\tfrac{\\alpha}{2}$ ) |qnorm(1 - $\\alpha$)|\n",
    " |   |reject $H_0$ if $z_0$ < $z_\\alpha$ |reject $H_0$ if abs($z_0$) > $z_\\tfrac{\\alpha}{2}$|reject $H_0$ if $z_0$ > $z_\\alpha$ |\n",
    " |p-value method:<br>Uses **p-value**  |---|---|---|\n",
    " |p-value                                       | P(Z < $z_0$)|P(Z > $|z_0|$)= P(Z < $z_0$) + P(Z > $z_0$)  |P(Z > $z_0$)   \n",
    " | |pnorm($z_0$, lower.tail=TRUE)|2 * pnorm(abs($z_0$), lower.tail=FALSE) |pnorm($z_0$, lower.tail=FALSE)|\n",
    " | |reject $H_0$ if p-val < $\\alpha$ |reject $H_0$ if p-val < $\\alpha$ |reject $H_0$ if p-val < $\\alpha$ |\n",
    " \n",
    " \n",
    " | |Traditional method|P-value method|\n",
    " |---|---|---|\n",
    " |reject $H_0$        |If test statistic $z_0$ $\\in$ critical region bounded by $z_\\alpha$ (or $z_\\tfrac{\\alpha}{2}$)|When p-val is low, $H_0$ must go [away]|\n",
    " |fail to reject $H_0$|If test statistic $z_0$ $\\not\\in$ critical region bounded by $z_\\alpha$ (or $z_\\tfrac{\\alpha}{2}$), fail to reject $H_0$  |When p-val is high $H_0$ must fly [works] |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "In continuous RV: P(x<?) is same as P(x$\\le$?)  \n",
    "\n",
    "\n",
    "Normal Distribution (same idea applies to T-distribution and $\\chi^2$-distribution, just different R functions):  \n",
    "P(Z $\\le$ $z_0$) = pnorm($z_0$)  \n",
    "P(Z $\\ge$ $z_0$) = pnorm($z_0$, lower.tail=FALSE) = 1 - P(Z $\\le$ $z_0$) = 1 - pnorm($z_0$)     \n",
    "P(Z > $|z_0|$) = P(Z $\\le$ $z_0$) + P(Z $\\ge$ $z_0$) = 2 $*$  P(Z $\\le$ $z_0$) (or 2 $*$ P(Z $\\ge$ $z_0$)) = 2*  pnorm($z_0$)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing using z test statistic (standard normal) - P-value method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.758036347776927"
      ],
      "text/latex": [
       "0.758036347776927"
      ],
      "text/markdown": [
       "0.758036347776927"
      ],
      "text/plain": [
       "[1] 0.7580363"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.241963652223073"
      ],
      "text/latex": [
       "0.241963652223073"
      ],
      "text/markdown": [
       "0.241963652223073"
      ],
      "text/plain": [
       "[1] 0.2419637"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.483927304446146"
      ],
      "text/latex": [
       "0.483927304446146"
      ],
      "text/markdown": [
       "0.483927304446146"
      ],
      "text/plain": [
       "[1] 0.4839273"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_0 = 0.7 #try z_0 = -0.7\n",
    "# left-tailed test,  all commands below are identical\n",
    "pnorm(z_0, lower.tail = TRUE)\n",
    "#1 - pnorm(-z_0, lower.tail = TRUE) # note the negative sing\n",
    "#1 - pnorm(z_0, lower.tail = FALSE) # note different tail\n",
    "\n",
    "# Right-tailed test, all commands below are identical\n",
    "1-pnorm(z_0, lower.tail = TRUE)\n",
    "#pnorm(-z_0, lower.tail=TRUE) # note the negative sing\n",
    "#pnorm(z_0, lower.tail=FALSE) # note different tail\n",
    "\n",
    "# Two-tailed test, all commands below are identical\n",
    "2 * pnorm(abs(z_0), lower.tail=FALSE)\n",
    "# 2 * pnorm(-z_0, lower.tail=TRUE) # if z_0 > 0\n",
    "# 2 * pnorm(z_0, lower.tail=TRUE) # if z_0 < 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing using z test statistic (standard normal) - Critical value method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "-1.55477359459685"
      ],
      "text/latex": [
       "-1.55477359459685"
      ],
      "text/markdown": [
       "-1.55477359459685"
      ],
      "text/plain": [
       "[1] -1.554774"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1.55477359459685"
      ],
      "text/latex": [
       "1.55477359459685"
      ],
      "text/markdown": [
       "1.55477359459685"
      ],
      "text/plain": [
       "[1] 1.554774"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1.88079360815125"
      ],
      "text/latex": [
       "1.88079360815125"
      ],
      "text/markdown": [
       "1.88079360815125"
      ],
      "text/plain": [
       "[1] 1.880794"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.0600000000000001"
      ],
      "text/latex": [
       "0.0600000000000001"
      ],
      "text/markdown": [
       "0.0600000000000001"
      ],
      "text/plain": [
       "[1] 0.06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha = 0.06 # when alpha = 0.5 i.e. 50% i.e. smack in the middle. alpha can NEVER be < 0, it's an area unde curve!\n",
    "\n",
    "# Left-tailed\n",
    "qnorm(alpha)\n",
    "\n",
    "#Right-tailed\n",
    "qnorm(1-alpha)\n",
    "\n",
    "#Two-tailed\n",
    "two_tailed_z_critical = qnorm(1 - alpha/2)\n",
    "two_tailed_z_critical\n",
    "# so interval becomes (- two_tailed_z_critical, + two_tailed_z_critical),\n",
    "# check with its inverse function, \n",
    "pnorm(-two_tailed_z_critical, lower.tail = TRUE) + pnorm(two_tailed_z_critical, lower.tail = FALSE) # equal to alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing using t test statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | Left-tailed|Two-tailed |Right-tailed |\n",
    " | --- | --- | --- | --- |\n",
    " |Null Hypotyhesis      |$H_0$ = ?   |$H_0$ = ?    |$H_0$ = ?    |\n",
    " |Alternative Hypothesis|$H_1$ < ?   |$H_0$ $\\ne$ ?|$H_1$ > ?    |\n",
    " |Confidence level      |(1-$\\alpha$)%    |(1-$\\alpha$)%|(1-$\\alpha$)%|\n",
    " |Traditional method:<br>Uses **critical value**    |---|---|---|\n",
    " |critical value|P(T<$t_{\\alpha, df}$) = $\\alpha$, find $t_{\\alpha, df}$  |P(T<$t_{\\tfrac{\\alpha}{2},df}$) = $\\tfrac{\\alpha}{2}$, find $t_{\\tfrac{\\alpha}{2},df}$  |P(T>$t_\\alpha$) = $\\alpha$, find $t_{\\alpha, df}$  | \n",
    " |   |qt($\\alpha$, df)|$\\pm$qt(1 - $\\tfrac{\\alpha}{2}$, df ) |qt(1 - $\\alpha$, df)|\n",
    " |   |reject $H_0$ if $t_0$ < $t_{\\alpha,df}$ |reject $H_0$ if abs($t_0$) > $t_{\\tfrac{\\alpha}{2},df}$|reject $H_0$ if $t_0$ > $t_{\\alpha,df}$ |\n",
    " |p-value method:<br>Uses **p-value**  |---|---|---|\n",
    " |p-value                                       | P(T < $t_0$)|P(T > $|t_0|$)= P(T < $t_0$) + P(T > $t_0$)  |P(T > $t_0$)   \n",
    " | |pt($t_0$, df, lower.tail=TRUE)|2 * pt(abs($t_0$), lower.tail=FALSE) |pt($t_0$, df, lower.tail=FALSE)|\n",
    " | |reject $H_0$ if p-val < $\\alpha$ |reject $H_0$ if p-val < $\\alpha$ |reject $H_0$ if p-val < $\\alpha$ |\n",
    " \n",
    " \n",
    " | |Traditional method|P-value method|\n",
    " |---|---|---|\n",
    " |reject $H_0$        |If test statistic $t_0$ $\\in$ critical region bounded by $t_{\\alpha, df}$ (or $t_{\\tfrac{\\alpha}{2},df}$)|When p-val is low, $H_0$ must go [away]|\n",
    " |fail to reject $H_0$|If test statistic $t_0$ $\\not\\in$ critical region bounded by $t_{\\alpha, df}$ (or $t_\\tfrac{\\alpha}{2}$), fail to reject $H_0$  |When p-val is high $H_0$ must fly [works] |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing using t test statistic - P-value method (same as z stat, just need df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.278196512316433"
      ],
      "text/latex": [
       "0.278196512316433"
      ],
      "text/markdown": [
       "0.278196512316433"
      ],
      "text/plain": [
       "[1] 0.2781965"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.721803487683567"
      ],
      "text/latex": [
       "0.721803487683567"
      ],
      "text/markdown": [
       "0.721803487683567"
      ],
      "text/plain": [
       "[1] 0.7218035"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.556393024632865"
      ],
      "text/latex": [
       "0.556393024632865"
      ],
      "text/markdown": [
       "0.556393024632865"
      ],
      "text/plain": [
       "[1] 0.556393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_0 = -0.7 #try t_0 = -0.7\n",
    "df = 2\n",
    "\n",
    "# left-tailed test,  all commands below are identical\n",
    "pt(t_0, df, lower.tail = TRUE)\n",
    "#1 - pt(-t_0, df, lower.tail = TRUE) # note the negative sing\n",
    "#1 - pt(t_0, df, lower.tail = FALSE) # note different tail\n",
    "\n",
    "# Right-tailed test, all commands below are identical\n",
    "1-pt(t_0, df, lower.tail = TRUE)\n",
    "# pt(-t_0, df, lower.tail=TRUE) # note the negative sing\n",
    "# pt(t_0, df, lower.tail=FALSE) # note different tail\n",
    "\n",
    "# Two-tailed test, all commands below are identical\n",
    "2 * pt(abs(t_0), df, lower.tail=FALSE)\n",
    "# 2 * pt(-t_0, df, lower.tail=TRUE) # if t_0 > 0\n",
    "# 2 * pt(t_0, df, lower.tail=TRUE) # if t_0 < 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing using t test statistic - Critical value method (same as z stat,  just need df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "-2.62016187037182"
      ],
      "text/latex": [
       "-2.62016187037182"
      ],
      "text/markdown": [
       "-2.62016187037182"
      ],
      "text/plain": [
       "[1] -2.620162"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2.62016187037182"
      ],
      "text/latex": [
       "2.62016187037182"
      ],
      "text/markdown": [
       "2.62016187037182"
      ],
      "text/plain": [
       "[1] 2.620162"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3.89642535976149"
      ],
      "text/latex": [
       "3.89642535976149"
      ],
      "text/markdown": [
       "3.89642535976149"
      ],
      "text/plain": [
       "[1] 3.896425"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.0600000000000001"
      ],
      "text/latex": [
       "0.0600000000000001"
      ],
      "text/markdown": [
       "0.0600000000000001"
      ],
      "text/plain": [
       "[1] 0.06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha = 0.06 # when alpha = 0.5 i.e. 50% i.e. smack in the middle. alpha can NEVER be < 0, it's an area unde curve!\n",
    "\n",
    "# Left-tailed\n",
    "qt(alpha, df)\n",
    "\n",
    "#Right-tailed\n",
    "qt(1-alpha, df)\n",
    "\n",
    "#Two-tailed\n",
    "two_tailed_t_critical = qt(1 - alpha/2, df)\n",
    "two_tailed_t_critical\n",
    "# so interval becomes (- two_tailed_t_critical, + two_tailed_t_critical),\n",
    "# check with its inverse function, \n",
    "pt(-two_tailed_t_critical, df, lower.tail = TRUE) + pt(two_tailed_t_critical, df, lower.tail = FALSE) # equal to alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing using F test statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| |Right-tailed |\n",
    " | --- | --- | \n",
    " |Null Hypotyhesis   |$H_0$ = ?    |\n",
    " |Alternative Hypothesis|$H_1$: At least one of the coefficients $\\ne$ 0      |\n",
    " |Confidence level       (1-$\\alpha$)%|\n",
    " |Traditional method:<br>Uses **critical value**    |---|\n",
    " |critical value |P(F>$F_\\alpha$) = $\\alpha$, find $F_{\\alpha, df1, df2}$  | \n",
    " |   |qf(1 - $\\alpha$, df1, df2)|\n",
    " |   |reject $H_0$ if $F_0$ > $F_{\\alpha,df1, df2}$ |\n",
    " |p-value method:<br>Uses **p-value**  |---|\n",
    " |p-value |P(F > $F_0$)   \n",
    " | |pf($F_0$, df1, df2, lower.tail=FALSE)|\n",
    " | |reject $H_0$ if p-val < $\\alpha$ |\n",
    " \n",
    " \n",
    " | |Traditional method|P-value method|\n",
    " |---|---|---|\n",
    " |reject $H_0$        |Reject $H_0$ if $F_{partial \\ or \\ overall} > F_{\\alpha, df1, df2}$  |When p-val is low, $H_0$ must go [away]|\n",
    " |fail to reject $H_0$|Fail to reject $H_0$ if $F_{partial \\ or \\ overall} \\le F_{\\alpha, df1, df2}$ |When p-val is high $H_0$ must fly [works] |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing using F test statistic - Critical value, P-value methods (need df1 and df2, always right-tailed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example (partial F for a subset of coefficients, can also do overall F for all coefficients):  \n",
    "$y_{full} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 +\\epsilon$  \n",
    "$y_{restricted} = \\beta_0 + \\beta_1 x_1 + \\epsilon$  \n",
    "  \n",
    "n = 22  \n",
    "restrictions = 2 = df1  \n",
    "k = 3  \n",
    "df2 = n-k-1 = 18  \n",
    "\n",
    "\n",
    "$H_0$: $ \\beta_2 =  \\beta_3 = 0$  \n",
    "$H_1$: At least one of the coefficients $\\ne$ 0  \n",
    "\n",
    "Critical value method: Reject $H_0$ if $F_{partial} > F_{\\alpha, df1, df2}$  \n",
    "P-value method: Reject $H_0$ if p-value < $\\alpha$, where p-value = $P(F > F_{partial})$, right-tail shaded area, and F $\\tilde{} F_{df1, df2}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "6.50467790509437"
      ],
      "text/latex": [
       "6.50467790509437"
      ],
      "text/markdown": [
       "6.50467790509437"
      ],
      "text/plain": [
       "[1] 6.504678"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "6.01290483480053"
      ],
      "text/latex": [
       "6.01290483480053"
      ],
      "text/markdown": [
       "6.01290483480053"
      ],
      "text/plain": [
       "[1] 6.012905"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.00748200247347742"
      ],
      "text/latex": [
       "0.00748200247347742"
      ],
      "text/markdown": [
       "0.00748200247347742"
      ],
      "text/plain": [
       "[1] 0.007482002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.01"
      ],
      "text/latex": [
       "0.01"
      ],
      "text/markdown": [
       "0.01"
      ],
      "text/plain": [
       "[1] 0.01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha = 0.01\n",
    "# F-test stat is always right-tail \n",
    "# see HW3 Self-Assessment example\n",
    "F_partial_2_18 = ((190.232 + 129.431)/2) / ((442.292)/18)\n",
    "F_alpha_2_18 =  qf((1-alpha), df1=2, df2=18) \n",
    "p_val_F_partial_2_18 = pf(F_partial_2_18, df1=2, df2=18, lower.tail=FALSE)\n",
    "\n",
    "# Critical value method\n",
    "F_partial_2_18\n",
    "F_alpha_2_18\n",
    "\n",
    "# p-value method\n",
    "p_val_F_partial_2_18\n",
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### R Functions and their defaults \n",
    "\n",
    "x, q : vector of quantiles  \n",
    "p: vector of probabilities  \n",
    "df or df1, df2: degrees of freedom  \n",
    "\n",
    "**The Normal Distribution**  \n",
    "dnorm(x, mean = 0, sd = 1, log = FALSE)  \n",
    "pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)  \n",
    "qnorm(p, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)  \n",
    "rnorm(n, mean = 0, sd = 1)  \n",
    "\n",
    "\n",
    "**The Student t Distribution Functions in R**   \n",
    "dt(x, df, ncp, log = FALSE) -  density, yields density function value in a given point  \n",
    "pt(q, df, ncp, lower.tail = TRUE, log.p = FALSE) - probability, yields CDF, i.e. probability of returning number smaller than an argument to this function  \n",
    "qt(p, df, ncp, lower.tail = TRUE, log.p = FALSE) -  quantile, inverse CDF, i.e. what value is at given quantile.  \n",
    "rt(n, df, ncp - random generation for the t distribution with df degrees of freedom (and optional non-centrality parameter ncp).  \n",
    "\n",
    "**The F Distribution**  \n",
    "df(x, df1, df2, ncp, log = FALSE)  \n",
    "pf(q, df1, df2, ncp, lower.tail = TRUE, log.p = FALSE)  \n",
    "qf(p, df1, df2, ncp, lower.tail = TRUE, log.p = FALSE)  \n",
    "rf(n, df1, df2, ncp)  \n",
    "\n",
    "**The (Non-Central) Chi-Squared Distribution**  \n",
    "dchisq(x, df, ncp = 0, log = FALSE)  \n",
    "pchisq(q, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)  \n",
    "qchisq(p, df, ncp = 0, lower.tail = TRUE, log.p = FALSE)  \n",
    "rchisq(n, df, ncp = 0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](normal-distrubution-large.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Example-of-Distribution-of-Sample-Means-all-3-situations.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**confidence interval** = point estimate $ \\pm $ Probability Distribution ptile  * SD of point estimate = (?, ?)  \n",
    "statistically significant ( 0 $ \\in $ interval)  \n",
    "statistically positive or statistically negative  (only +ve or only -ve values $ \\in $ interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**prediction interval**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **prediction interval** should not be confused with a confidence interval for a fitted value, which will be narrower. \n",
    "\n",
    "The prediction interval is used to provide an interval estimate for a prediction of $y$ for one member of the population with a particular value of $x_0$;  \n",
    "The confidence interval is used to provide an interval estimate for the true average value of $y$ for all members of the population with a particular value of $x_0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~ depending on the context: sigma can be of population, of linear regression error (aka variance of deviances $\\epsilon$), etc ~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLR:  \n",
    "~ Theoretical model:  \n",
    "     $\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\large y =\\beta_0 + \\beta_1x + \\epsilon$  \n",
    "     $\\large E[y|x] =\\beta_0 + \\beta_1x$  \n",
    "       \n",
    "~ Least squares line:  \n",
    "     $\\large \\hat y =  \\hat\\beta_0 + \\hat\\beta_1x$   \n",
    "      \n",
    "~ Residuals:  \n",
    "    $\\large e_{i} = \\hat\\epsilon_i = y_i - \\hat y_i = y_i - (\\hat\\beta_0 + \\hat\\beta_1x)$\n",
    "\n",
    "ANOVA:  \n",
    "~ Residuals $\\large\\hat\\epsilon_i = Y_{ij} - \\hat\\mu_i$, for i groups, j elements in each~  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~error term can be from the theoretical model $y$ = $\\beta_0$ + $\\beta_1$x + $\\epsilon$  \n",
    "or it can be from the fittel model (also called residuals or deviances) $y$ =  $\\hat\\beta_0$ + $\\hat\\beta_1$x + $\\hat\\epsilon$, where $\\hat\\epsilon$ is also written as e (Roman letter) (notice all estimators of parameters have hats on them).  \n",
    "\n",
    "~ Note that $\\hat\\sigma^2$  is the estimate of the **variance of the error term** (i.e we may not know true $\\epsilon$ and its $\\sigma$, we can only estimate them using $\\hat\\epsilon$ and its $\\hat\\sigma$).~\n",
    " \n",
    " Mean Squared Error MSE of regression = $\\large\\hat\\sigma^2 =\\frac{\\sum_{i=1}^{n} \\hat\\epsilon_{i}}{n-k} = \\frac{\\text{Sum of Squared Errors SSE}}{n-k}$, where k=number of variables in the regression due to which we lose degrees of freedom (such as intercept  $\\beta_0$,  $\\beta_1$). Note that while $\\sigma$ is one of the parameters of the regression, we do not lose a degree of freedom because of it.\n",
    " \n",
    " \n",
    " ~In a regression model, the predictor variables (aka X-variables, explanatory variables, covariates, etc.) are assumed to be fixed and known. They are not assumed to be random. All of the randomness in the model is assumed to be in the error term. Consider a simple linear regression model as standardly formulated: $Y = \\beta_0 + \\beta_1 X + \\varepsilon, \\text{ where } \\varepsilon\\sim\\mathcal N(0, \\sigma^2)$. The error term, $\\epsilon$, is a random variable and is the source of the randomness in the model. As a result of the error term, Y is a random variable as well. But X is not assumed to be a random variable. (Of course, it might be a random variable in reality, but that is not assumed or reflected in the model.)~\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~**sampling distribution**, which will yield the **confidence interval**, which is immediately analogous to the **test statistic**.~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Regression Analysis Model (vs Optimization):\n",
    "\n",
    "Response variable, aka dependent variable, aka predict**ed** variable -is a Random Variable \n",
    "    - Varies with changes in predictors, along with random changes  \n",
    "    - error term in regression is also a RV\n",
    "Predict**ing** variable, aka independent variable, aka predictor - Fixed Variable (even though in real life it's also RV) \n",
    "    - Does not change with response, but is set fixed before the response is measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Simple Linear Regression / Multiple Linear Regression - Assumptions Checks:\n",
    "! note: In science, an empirical relationship or phenomenological relationship is a relationship or correlation that is supported by experiment and observation but not necessarily supported by theory. In regression modeling, we are looking for an empirical relationship between a response and one or more predictor variables\n",
    "! note: SLR/MLR are your garden variety Ordinary Least Squares regression. OLS relies on constant variance assumption, if this is violated - see Weighted Least Squares.    \n",
    "! note: most plots are used in both SLR and ANOVA assumption checks. not sure if E[$\\epsilon_{i}$] = 0  or E[$\\hat{\\epsilon_{i}}$] = 0, similarly: not sure if Var[$\\epsilon_{i}$] = $\\sigma^2$  or Var[$\\hat{\\epsilon_{i}}$] = $\\sigma^2$    \n",
    "! etc. My guess is probably both, since $\\hat{\\epsilon_{i}}$ are \"estimates\" of $\\epsilon_{i}$\n",
    "\n",
    "! note: fitted values vs residuals to identify nonlinearity, nonconstant variance, and presence of outliers  \n",
    "! note: possible variations: x vs y, x vs $e_{i}$, y vs $e_{i}$, $\\hat{y_{i}}$ vs $e_{i}$\n",
    "\n",
    "! note: plot a vs b in my notes means plot a on the x-asix and b on the y-axis.  \n",
    "! note: residuals = observed y - model-fitted y = $y_{i}$ - $\\hat{y_{i}}$ = $\\hat{\\epsilon_{i}}$ = $e_{i}$  \n",
    "! note: residuals vs fitted plot has same interpretation as residuals vs predictor  \n",
    "! SLR: 1 intercept and 1 var, MLR: 1 intercept and many variables. ?? Best to plot $\\hat{y}$ vs $e$ instead of x vs $e$  because there are many x     \n",
    "! note: SLR - marginal model, MLR -conditional model. Coefficients for the same variable in these 2 models can differ drastically in sign, magnitude, even significance.  \n",
    "**! note: in lecture notes, Dr Serban uses residuals plot in SLR, but standardized residuals plot in MLR to assess constant variance assumption. In MLR, the rest of the assumptions diagnosed with plots of smth vs residuals don't need to be using standardized ones.**  \n",
    "\n",
    "**SLR/MLR Objectives**\n",
    "1. Prediction of response for new observation (\"setting\"), \n",
    "2. Model the relationship between response var and predicting vars\n",
    "3. Testing hypotheses (plural) on association relationships\n",
    "\n",
    "### Linearity Assumption (between x and y)  \n",
    "Means that E[$\\epsilon_{i}$] = 0  \n",
    "Violation leads to difficulties in estimating $\\beta_{0}$, and that means that your model does not include a necessary systematic component.  \n",
    "(May need a transformation of just predicting var(s) x or both x and response y)\n",
    "- Scatterplot of predicting vs predicted variable (x vs y)\n",
    "    - A straight-ish line, going diagonally, either up or down\n",
    "- **Scatterplot of predicting variable vs model residuals** (x vs $e$ )\n",
    "    - No pattern in the residuals with respect to predicting var, scattered around 0 (on y-axis)\n",
    "    - If doing transformations, compare correlation coeffiecient before and after\n",
    "- *Scatterplot of fitted values vs residuals* ($\\hat{y}$ vs $e$) (PennState notes)\n",
    "    - No patterns, scattered around 0 (on y-axis)\n",
    "    \n",
    "Linearity assumption of categorical (aka qualitative) variables vs response - only need/can to assess linearity of quantitative variables with respect to response. The means of response will vary per category, and whether they are statistically different can be checked by TukeyHSD command in R).    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant Variance Assumption  \n",
    "Means that Var[$\\epsilon_{i}$] = $\\sigma^2$  \n",
    "Violations means estimates are not as efficient as they could be in estimating the true parameters, poor prediction intervals.  \n",
    "May need to do a transformation on respone var (aka lambda transformation, aka Box-Cox transformation)  \n",
    "- *Scatter plot of the fitted values against the residuals.*($\\hat{y}$ vs $e$), (can also do y vs $e$)  \n",
    "    - (NOT megaphone shape) the variance is not larger for larger fitted values\n",
    "- **Scatterplot of predicting variable vs model residuals** (x vs $e$ )\n",
    "    - (NOT megaphone shape) the variance is not larger for larger predicting variable values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independence assumption - CANNOT ASSESS WITH THIS PLOT  \n",
    "Means that {$\\epsilon_{1}$, $\\epsilon_{2}$, ..., $\\epsilon_{n}$} are independent Random Variables (RV).  \n",
    "Means that the deviances, or in fact the response variables y’s, are independently drawn from the data-generating process.  \n",
    "Violation of this assumption can lead to very misleading assessments of the strength of the regression. This violation most often occurs in data that are ordered in time, like in time series data: auto-correlation.  \n",
    "### Uncorrelated Errors - SETTLE FOR THIS \n",
    "- *Scatter plot of the fitted values against the residuals.*($\\hat{y}$ vs $e$), (can also do y vs $e$)  \n",
    "    - NO Clusters/groupings of the residuals\n",
    "- **Scatterplot of predicting variable vs model residuals** (x vs $e$ ) \n",
    "\n",
    "'*Residual analysis does not check for the independence assumption. Remember, the assumption is independence, not uncorrelated errors. But all we can assess with residual analysis is uncorrelated errors. Independence is more complicated to evaluate. If the data are from a randomized trial, the independence is established. But most data you're going to apply regression on are from observational studies and thus independence does not hold. In those cases, we're going (residual analysis is going to) to assess uncorrelated errors, not independent errors.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality Assumption Check  \n",
    "Means that $\\epsilon_{i}$ ~ Normal, (thus $Y_{i}$ ~ Normal - lots of controversy on this one: $Y_{i}$ ~ Normal **given / conditional on values of X(s)**)  \n",
    "This is needed if we want to do any confidence or prediction intervals, or hypothesis test, which we usually do.  \n",
    "Violation makes hypothesis test and confidence and prediction intervals misleading  \n",
    "(May need to do a transformation on respone var (aka lambda transformation, aka Box-Cox transformation))\n",
    "- Q-Q plot\n",
    "    - Roughly a diagonal line\n",
    "- Histogram\n",
    "    - Symmetric, no gaps, hopefully only 1 mode (if more - possibly selection bias, may need a control variable)\n",
    "        - If there are multiple modes present, a categorical variable controlling for bias may be lacking\n",
    "  \n",
    "! note: A common misconception about linear regression is that it assumes that the outcome Y is normally distributed. Actually, linear regression assumes normality for the residual errors $\\epsilon$, which represent variation in Y which is not explained by the predictors. It may be the case that marginally (i.e. ignoring any predictors) Y is not normal, but after removing the effects of the predictors, the remaining variability, which is precisely what the residuals represent, are normal, or are more approximately normal. [Dr Serban:  Y is normally distributed given X's.]  \n",
    "http://thestatsgeek.com/2013/08/07/assumptions-for-linear-regression/\n",
    "\n",
    "\n",
    "! note: It is reasonable for the residuals in a regression problem to be normally distributed, even though the response variable is not. Consider a univariate regression problem where y∼N(βx,σ^2). so that the regression model is appropriate, and further assume that the true value of β=1. In this case, while the residuals of the true regression model are normal, the distribution of y depends on the distribution of x, as the conditional mean of y is a function of x. If the dataset has a lot of values of x that are close to zero and progressively fewer the higher the value of x, then the distribution of y will be skewed to the left. If values of x are distributed symmetrically, then y will be distributed symmetrically, and so forth. **For a regression problem, we only assume that the response is normal conditioned on the value of x.**  \n",
    "https://stats.stackexchange.com/questions/12262/what-if-residuals-are-normally-distributed-but-y-is-not\n",
    "\n",
    "! note: predictors are not checked for normality, BUT if a predictor is strongly skewed, linearity with respect to response may not hold for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "## ANOVA - Assumptions Checks:\n",
    "`anova (lm(y ~ x))` or `anova (aov(y ~ x))` - answers the following question: are mean responses y of k groups within a qualitative variable x statistically different?  \n",
    "$H_0: \\mu_1 = \\mu_2 =...= \\mu_k$  \n",
    "$H_1:$ At least one of the $\\mu_i$ is different from the rest  \n",
    "  \n",
    "`TukeyHSD(aov(y ~ x))` answers WHICH pairs of means are statistically different  \n",
    "For all categories k within a categorical variable x:  \n",
    "$H_0: \\mu_{a,k} - \\mu_{b,k} = 0$    \n",
    "$H_1: \\mu_{a,k} - \\mu_{b,k} \\ne 0$    \n",
    "  \n",
    "! note: most plots are used in both SLR and ANOVA assumption checks.  \n",
    "! note: residuals = observed Y  - estimated mean for the group =  $Y_{ij}$ $-$ $\\hat{\\mu_{i}}$ = $\\hat{\\epsilon_{ij}}$ = $e_{ij}$  \n",
    "! note: plot residuals for each treatment group\n",
    "! note:   aov() is a wrapper for the lm() function that produces an object that is basically an enhanced version of the model that would be produced by lm(). use either lm() or aov() to produce the model, and then pass that model to anova() to analyse it.  \n",
    "\n",
    "**ANOVA objectives:**  \n",
    "1. Compare vatiability within group to variability between groups\n",
    "2. Testing for equal means ($\\mu_1 = \\mu_2 = ... = \\mu_k$)\n",
    "3. Estimation of simultaneous confidence intervals for differences of means ($\\mu_i - \\mu_j = 0$, for i,j = 1...k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO Linearity Assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant Variance Assumption  \n",
    "Means that Var[$\\epsilon_{ij}$] = $\\sigma^2$  \n",
    "Violation makes inference on equality of means unreliable  \n",
    "- *Scatter plot of the fitted values against the residuals.*($\\hat{y}$ vs $e$)\n",
    "    - (NOT megaphone shape) the variance is not wider **across groups** - this may be hard to achieve (e.g. response of control group vs some form of treatment group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independence assumption - CANNOT ASSESS WITH THIS PLOT  \n",
    "Means that {$\\epsilon_{1}$, $\\epsilon_{2}$, ..., $\\epsilon_{n}$} are independent Random Variables (RV).  \n",
    "Means that the deviances, or in fact the response variables y’s, are independently drawn from the data-generating process.  \n",
    "\n",
    "\n",
    "### Uncorrelated Errors - SETTLE FOR THIS \n",
    "- Scatterplot of order of data collection (in time or space) vs residuals\n",
    "    - Residuals randomly scattered around 0 (on y-axis), no patterns\n",
    "\n",
    "- *Scatter plot of the fitted values against the residuals.*($\\hat{y}$ vs $e$)\n",
    "    - NO clusters of errors **within groups**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality Assumption Check  \n",
    "Means that $\\epsilon_{1}$ ~ Normal, (thus $Y_{ij}$ ~ Normal)\n",
    "- Q-Q plot\n",
    "    - Roughly a diagonal line\n",
    "- Histogram\n",
    "    - Symmetric, no gaps\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ConstantVarViolation_SLR_vs_ANOVA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Skewness.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable types\n",
    "- Controlling (control for selection bias)\n",
    "    - Control variables are usually variables that you are not particularly interested in, but that are related to the dependent variables. You want to remove their effects from the equation. Consider, for example, you are interested in the difference in height of people from different countries. You could gather a sample of people from different countries and measure them and compare the heights. But you'd probably want to control for some other variables that are known to relate to height (e.g. gender). A controlling variable ??is a type confounding variables.  \n",
    "- Explanatory (explain variability)\n",
    "    - explanatory variables aims to explain the variability in response with variability in predicting variables\n",
    "- Predictive (minimize prediction error)\n",
    "    - predictive variables aim to minimize the prediction error \n",
    "- (NEW!) Confounding variables / omitted variables\n",
    "    - They correlate with response and predictor(s). Need to be accounted for, if possible.  \n",
    "\n",
    "TL;DR: peole f\\*ck up definitions of controlling and confounding variables.\n",
    "\n",
    "There is a trade-off between bias and variance of the fitted model. With more predictors, the fitted model has smaller bias and larger variance, which implies although the mean estimated response is close to the ground truth, we are less confident (the confidence interval is wide) in a single prediction because of the large variance. On the other hand, less predictors result in larger bias with smaller variance. This time, the mean estimated response deviates farther from the ground truth, but we are more confident in the prediction.\n",
    "  \n",
    "  \n",
    "**Qualitative vs Quantitative:**  \n",
    "Generally, can transform quantitative var into qualitative (e.g. when there is a non-linear relationship of that quant var with respect to response, e.g. when there are not a lot of observations for that variable, i.e. the year the movie was releases - if our data spans a small number of years, consider making years a categorical var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Decompositions and F-tests\n",
    "- Ways to test sifnificance of coefficient estimates:\n",
    "    - ANOVA F-test on regression coefficient(s) - see below\n",
    "    - t-test of the coefficient or its associated p-value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SLR Error Decomposition  \n",
    "- Sum Square Errors SSE aka Sum Square Residuals (very confusing!)  \n",
    "- n observations, k=2 coefficients, i.e. slope and intercept \n",
    "-  $y = \\beta_0 + \\beta_1 x_1 + \\epsilon$\n",
    "  \n",
    "$\\large \\text{Sum Square Total SST = Sum Square Errors SSE (also SSResiduals) + Sum Square Regression SSReg (also SSExplained}) $\n",
    "  \n",
    "$\\large \\sum_{i=1}^n (y_i-\\bar y)^2 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ =\\sum_{i=1}^n (y_i-\\hat y_i)^2 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ +\\sum_{i=1}^n (\\hat y_i-\\bar y)^2$  \n",
    "  \n",
    "$\\large R^2 = 1 - \\tfrac{SSE}{SST} =  \\tfrac{SST}{SST} -  \\tfrac{SSE}{SST} =  \\tfrac{SSR}{SST}$   \n",
    "$\\large MSE = \\tfrac{SSE}{n-k} = \\tfrac{SSE}{n-2} = \\hat\\sigma^2$  \n",
    "$\\large MSR = \\tfrac{SSR}{k-1} = \\tfrac{SSR}{1}$  \n",
    "$\\large MST = \\tfrac{SST}{n-1}$  \n",
    " \n",
    " ### SLR F-test\n",
    "H0:  $\\beta_1 = 0$, notice that $\\beta_0$ is not a part of it.    \n",
    "H1:  $\\beta_1 \\ne 0$  \n",
    "$\\text{F-test test statistic } F_{0}= \\tfrac{MSR}{MSE} = \\tfrac{SSR\\ /\\ k -1}{SSE\\ /\\ n-k} \\tilde{} F_{k-1, n-k}$  \n",
    "\n",
    "Critical value method: Reject H0 if $F_{0} > F_{\\alpha, k-1, n-k}$, a critical value depending on $\\alpha$, df1, df2  \n",
    "P-value method: Reject H0 if p-value < $\\alpha$, where p-value = $P(F > F_0)$, right-tail shaded area, and F $\\tilde{} F_{k-1, n-k}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-way ANOVA Error Decomposition \n",
    "- k samples/groups with i=1 through k and $n_i$ elements in each group with j=1 through $n_i$  \n",
    "  \n",
    "|...............per sample/group mean...............|...............overall mean...............|\n",
    "| ---  | ---  |\n",
    "|$\\large \\hat\\mu_{i} = \\bar Y_{i} = \\tfrac{\\sum_{j=1}^{n_i}Y_{ij}}{n_i}$|$\\large \\bar Y_{..}=\\tfrac{\\sum_{i=1}^{k}\\sum_{j=1}^{n_i} Y_{ij}}{N}$|\n",
    "\n",
    "$\\large \\text{Sum Square Total SST = Sum Square Errors SSE + Sum Square due to Treatment } SST_R $  \n",
    "$\\large  \\sum_{i=1}^{k} \\sum_{j=1}^{n_i}(Y_{ij} - \\bar Y_{..})^2 \\ \\ =     \n",
    "\\sum_{i=1}^{k} \\sum_{j=1}^{n_i} (Y_{ij} - \\bar Y_i)^2 \\ \\ \\ \\ \\\n",
    "+ \\sum_{i=1}^{k} n_i (\\bar Y_{i} - \\bar Y_{..})^2$  \n",
    "\n",
    "$\\large MSE = \\tfrac{SSE}{N-k}$ = within-group variability, lost k degrees of freedom due to k group means  \n",
    "$\\large MST_R = \\tfrac{SST_R}{k-1}$ = between-group variability    \n",
    "$\\large MST = \\tfrac{SST}{N-1}$, lost 1 degree of freedom for substituting group mean with the overall mean  \n",
    "  \n",
    "  \n",
    "#### Variances in one-way ANOVA:  \n",
    "$\\large s_{pool}^2$  aka $\\large \\hat \\sigma^2$ (general notation) aka MSE (concept) are estimators of $\\sigma^2$  \n",
    "$\\large \\hat \\sigma^2 = \\tfrac{\\sum_{i=1}^{k} \\sum_{j=1}^{n_i} (Y_{ij} - \\bar Y_i)^2}{N-k} = \\tfrac{SSE}{N-k}$ = MSE, lost k degrees of freedom due to k group means  \n",
    "$\\large s_{0}^2 =  \\tfrac{\\sum_{i=1}^{k} \\sum_{j=1}^{n_i} (Y_{ij} - \\bar Y_{..})^2}{N-1} = \\tfrac{SST}{N-1}$ = MST, lost 1 degree of freedom for substituting group mean with the overall mean    \n",
    "\n",
    "### One-way ANOVA F-test \n",
    "- aka MLR (w/ intercept) F-test for all non-intercept regression coefficients\n",
    "- k groups/samples/labels - one factor \n",
    "- N = total number of observations, $n_i$ = number of records within each group\n",
    "- $N = n_1 + n_2 + ... + n_k$\n",
    "      \n",
    "One-way ANOVA is an MLR with 1 categorical variable with k groups, transformed to dummy variables \n",
    "- k-1 dummy vars in an intercept model: $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2+ ... + \\beta_{k-1} x_{k-1} + \\epsilon$\n",
    "- k dummy variables in a no-intercept model: $y =\\beta_1 x_1+ \\beta_2 x_2 + ... + \\beta_{k} x_k + \\epsilon$\n",
    "\n",
    "\n",
    "ANOVA version:  \n",
    "H0: $\\mu_1 = \\mu_2 = ... = \\mu_k$  \n",
    "H1:At least one mean different from the rest  \n",
    "\n",
    "??MLR version (regular, w/ intercept) / SLR with 1 categorical var converted to factor (aka dummy variables)     \n",
    "H0:  $\\beta_1 = \\beta_2 = ...= \\beta_{k-1} = 0$, notice that $\\beta_0$ is not a part of it.    \n",
    "H1: At least one of the coefficients is different than 0.\n",
    "\n",
    "$\\text{F-test test statistic } F_{0}=  \\tfrac{\\text{between-group variability}}{\\text{within-group variability}} = \\tfrac{MST_R}{MSE} = \\tfrac{SST_R\\ /\\ k -1}{SSE\\ /\\ N-k} \\tilde{} F_{k-1, N-k}$  \n",
    "\n",
    "Critical value method: Reject H0 if $F_{0} > F_{\\alpha, k-1, N-k}$, a critical value depending on $\\alpha$, df1, df2  \n",
    "P-value method: Reject H0 if p-value < $\\alpha$, where p-value = $P(F > F_0)$, right-tail shaded area, and F $\\tilde{} F_{k-1, N-k}$ \n",
    "\n",
    "\n",
    "### TukeyHSD\n",
    "Which of the means are statistically different?  \n",
    "TukeyHSD computes differences in all pairs of means and looks whether the (1-$\\alpha$)% confidence interval contains 0.  \n",
    "If it does, the difference between two given means is not statistically different than 0 (i.e. the difference is 0), thus the two given means are equal.  \n",
    "If it does not, the two means are statistically different from each other.\n",
    "\n",
    "### Two-way ANOVA - have not studied\n",
    "- k groups/samples/labels - one factor\n",
    "- 2 subgroups for each of the k groups - second factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLR Error Decomposition\n",
    "- Sum Square Errors SSE aka Sum Square Residuals (very confusing!)\n",
    "- k = p + 1, i.e. p variables and 1 intercept\n",
    "\n",
    "  \n",
    "$\\large \\text{Sum Square Total SST = Sum Square Errors SSE + Sum Square Regression SSR} $\n",
    "  \n",
    "$\\large \\sum_{i=1}^n (y_i-\\bar y)^2 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ =\\sum_{i=1}^n (y_i-\\hat y_i)^2 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ +\\sum_{i=1}^n (\\hat y_i-\\bar y)^2$  \n",
    "  \n",
    "$\\large R^2 = 1 - \\tfrac{SSE}{SST} =  \\tfrac{SST}{SST} -  \\tfrac{SSE}{SST} =  \\tfrac{SSR}{SST}$  \n",
    "  \n",
    "$\\large MSE = \\tfrac{SSE}{n-k} = \\tfrac{SSE}{n-p-1} = \\hat\\sigma^2$  \n",
    "$\\large MSR = \\tfrac{SSR}{k-1} = \\tfrac{SSR}{p}$  \n",
    "$\\large MST = \\tfrac{SST}{n-1}$  \n",
    "\n",
    "### MLR (w/ intercept) F-test on all non-intercept cofficients\n",
    "- aka ANOVA for all non-intercept cofficients  \n",
    "- k= p + 1, i.e. p variables and 1 intercept\n",
    "- $y = \\beta_0 + \\beta_1 x_1+ \\beta_2 x_2 + ... + \\beta_{p} x_p + \\epsilon$\n",
    "   \n",
    "H0:  $\\beta_1 = \\beta_2 = ...= \\beta_{p} = 0$, notice that $\\beta_0$ is not a part of it.    \n",
    "H1: At least one of the coefficients is different than 0.\n",
    "\n",
    "$\\text{F-test test statistic } F_{0}= \\tfrac{MSR}{MSE} = \\tfrac{SSR\\ /\\ p}{SSE\\ /\\ n-p-1} \\tilde{} F_{p, n-p-1}$  \n",
    "\n",
    "Critical value method: Reject H0 if $F_{0} > F_{\\alpha, p, n-p-1}$, a critical value depending on $\\alpha$, df1, df2  \n",
    "P-value method: Reject H0 if p-value < $\\alpha$, where p-value = $P(F > F_0)$, right-tail shaded area, and F $\\tilde{} F_{p, n-p-1}$ \n",
    "\n",
    "\n",
    "### MLR (w/ intercept ) partial F-test\n",
    "- aka ANOVA for a subset of regression coefficients, full model: controlling + other variables vs reduced model: just controlling variables  \n",
    "- k= p + q + 1, i.e. p controlling factors, q explanatory factors, 1 intercept \n",
    "- $y = \\beta_0 + (\\beta_1 x_1+ \\beta_2 x_2 + ... + \\beta_{p} x_p) + (\\alpha_1 z_1+ \\alpha_2 z_2 + ... + \\alpha_{q} z_q) + \\epsilon$\n",
    "\n",
    "H0: $\\alpha_1 = \\alpha_2 = ... = \\alpha_q = 0$  \n",
    "H1: At least one of the coefficients for explanatory factors is different than 0\n",
    "\n",
    "$ \\text{Partial F-test test statistic } F_{partial}$ =$\\tfrac {SSR (z_1, .., z_q | x_1, ..., x_p) \\ /\\ q}{SSE (z_1, .., z_q, x_1, ..., x_p) \\ /\\ n-p-q-1} $\n",
    "\n",
    "Critical value method: Reject H0 if $F_{partial} > F_{\\alpha, q, n-p-q-1}$, a critical value depending on $\\alpha$, df1, df2  \n",
    "P-value method: Reject H0 if p-value < $\\alpha$, where p-value = $P(F > F_{partial})$, right-tail shaded area, and F $\\tilde{} F_{q, n-p-q-1}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R commands: anova(fullmodel, reducedmodel)  \n",
    "R command: anova(fullmodel) - to get the values for the partial F-test stat (see lecture notes data example 3.4.1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervals and Distributions\n",
    "- note! In order to make statistical inference on the regression coefficients, we need to estimate the variance of the error terms (aka MSE, aka $\\hat\\sigma^2$), which gives us the standard deviation of the regression coefficient estimate (aka standard error); we also need normality assumption to hold to make inferences.  \n",
    "- note! $\\hat\\beta_i$ are a linear combination of normally distributed RV, so it's also normally distributed; but it's sampling distribution is a t-distribution (because we substitute $\\sigma$ with $\\hat\\sigma$)  \n",
    "- note! because $\\hat\\beta_i$ are normally distributed, so it $\\hat y$; but it's sampling distribution is a t-distribution (because we substitute $\\sigma$ with $\\hat\\sigma$); if we do know $\\sigma$, it's sampling distribution is normal.   \n",
    "    - variance of $\\bf\\hat y | x^*$  is smallest if we look at regression line in the middle of the range of x, i.e. when $x^* = \\bar x$. As $x^*$ moves away from $\\bar x$, in either direction, the variance increases (see formula to prove to self). Because variance is used to calculate confidence/prediction intervals, those too get wider as  $x^*$ moves away from $\\bar x$. \n",
    "\n",
    "**SLR, k=2 (same applies to MLR, k > 2):**    \n",
    "(1) $e_i = \\hat\\epsilon_i = y_i - \\hat y_i = y_i = (\\hat\\beta_0 + \\hat\\beta_1 x_i)$  \n",
    "(2) $\\hat\\sigma^2 = \\tfrac{\\sum (\\hat\\epsilon_i)^2}{n-k}$  \n",
    "(3) Assumption $\\hat\\epsilon_i \\tilde{} \\epsilon_i \\tilde{} N(0, \\sigma^2) $  \n",
    "(4) Because we will never know $\\beta_0$ and $\\beta_1$, substitute $\\hat\\beta_0$ and $\\hat\\beta_1$ instead  \n",
    "(5) Then $\\hat\\sigma^2 \\tilde{} \\chi_{n-k}^2$, loosing k=2 degrees of freedom for each substitution \n",
    "  \n",
    "$\\bf \\hat\\beta_1$  \n",
    "If (3) and (5) then $\\hat\\beta_1 \\tilde{} N(\\beta_1, \\tfrac{\\sigma^2}{S_{xx}})$, but we may not know $\\sigma^2$, must substitute with $\\hat\\sigma^2$  \n",
    "So $\\tfrac{\\hat\\beta_1 - \\beta_1}{\\sqrt{\\tfrac{\\hat\\sigma^2}{S_{xx}}}} \\tilde{} t_{n-k}$ and thus Confidence Interval for $\\hat\\beta_1$ =\n",
    "$(\\hat\\beta_1 \\pm t_{\\tfrac{\\alpha}{2},n-k} \\sqrt{\\tfrac{\\hat\\sigma^2}{S_{xx}}}) = (\\hat\\beta_1 \\pm t_{\\tfrac{\\alpha}{2},n-k} \\text{ s.e.} (\\hat\\beta_1))$ (! assuming normality of residuals / response var **given x's**)\n",
    "\n",
    "$\\bf\\hat\\beta_0$  \n",
    "$\\hat\\beta_0 = \\bar y - \\hat\\beta_1 x_1$  \n",
    "Confidence Interval for $\\hat\\beta_0$ =\n",
    "$(\\hat\\beta_0 \\pm t_{\\tfrac{\\alpha}{2},n-k} \\sqrt{\\hat\\sigma^2 (\\tfrac{1}{n} +\\tfrac{\\bar x^2}{S_{xx}}}) = (\\hat\\beta_0 \\pm t_{\\tfrac{\\alpha}{2},n-k} \\text{ s.e.} (\\hat\\beta_0)) $ (! assuming normality of residuals / response var **given x's**)  \n",
    "\n",
    "$\\bf\\hat y | x^*$  \n",
    "Confidence interval = $(\\hat y|x^* \\pm t_{\\tfrac{\\alpha}{2}, n-k} \\sqrt{ \\hat\\sigma^2( \\tfrac{1}{n} + \\tfrac{(x^* - \\bar x)^2}{S_{xx}})}) = (\\hat y|x^* \\pm t_{\\tfrac{\\alpha}{2}, n-k} \\text{s.e. } (\\hat y | x^*))$ (! assuming normality of residuals / response var **given x's**)    \n",
    "Prediction interval = $(\\hat y|x^* \\pm t_{\\tfrac{\\alpha}{2}, n-k} \\sqrt{ \\hat\\sigma^2(1 + \\tfrac{1}{n} + \\tfrac{(x^* - \\bar x)^2}{S_{xx}})}) = (\\hat y|x^* \\pm t_{\\tfrac{\\alpha}{2}, n-k} \\text{s.e. } (\\hat y | x^*))$  (! assuming normality of residuals / response var **given x's**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-way ANOVA**  \n",
    "The individual sample variances for the k samples have a chi-square distribution because we assume that the data are normally distributed (see below: Sample Variance Estimator). An important property of the chi-square distribution is that, if we have independent chi-squared random variables, their sum is also a chi-square distribution.  \n",
    "\n",
    "\n",
    "Assume response var y (e.g. height) is normally distributed given predicting var x (e.g. voice pitch)  \n",
    "That is $Y_{1,i}, Y_{2,i}, ..., Y_{n,i} \\tilde{} N(\\mu_i, \\sigma^2$)  \n",
    "Then $s_{1}^2, s_{2}^2, ..., s_{k}^2$ are $\\chi^2$  \n",
    "Assume $\\sigma^2$ is constant across all k samples/groups  \n",
    "$\\tfrac{\\text{SSE}}{\\sigma^2} = \\tfrac{n_1 - s_1^2}{\\sigma^2} + ... +\\tfrac{n_k - s_k^2}{\\sigma^2} \\tilde{} \\chi_{N-k}^2$  \n",
    "$\\text{MSE} = \\hat\\sigma^2 = \\tfrac{\\text{SSE}}{N-k} \\tilde{} \\chi_{N-k}^2$\n",
    "\n",
    "  \n",
    "Assume response var y (e.g. height) is normally distributed given predicting var x (e.g. voice pitch)  \n",
    "That is $Y_{1,i}, Y_{2,i}, ..., Y_{n,i} \\tilde{} N(\\mu_i, \\sigma^2$)   \n",
    "Then $ \\hat\\mu_{i} = \\bar Y_{i} = \\tfrac{\\sum_{j=1}^{n_i}Y_{ij}}{n_i} \\tilde{} N(\\mu_i, \\tfrac{\\sigma^2}{n_i}) $  \n",
    "However, we do not know $\\sigma^2$, we replace it with $\\hat\\sigma^2$  \n",
    "So $\\tfrac{\\hat\\mu_i - \\mu_i}{\\sqrt{\\tfrac{\\hat\\sigma^2}{n_i}}} \\tilde{} t_{N-k}$ and thus Confidence Interval for means:\n",
    "$(\\hat \\mu_i \\pm  t_{\\tfrac{\\alpha}{2}, N-k} \\sqrt{\\tfrac{\\hat\\sigma^2}{n_i}}) = (\\hat \\mu_i \\pm  t_{\\tfrac{\\alpha}{2}, N-k} \\text{s.e. }(\\hat \\mu_i ))$\n",
    "\n",
    "Summary:  \n",
    "sampling distribution of MSE = $\\hat\\sigma^2 = s_{pool}^2 \\tilde{} \\chi_{N-k}^2$  \n",
    "sampling distribution of $s_{0}^2 \\tilde{} \\chi_{N-1}^2$  \n",
    "sampling distribution of $\\tfrac{\\hat\\mu_i - \\mu_i}{\\sqrt{\\tfrac{\\hat\\sigma^2}{n_i}}} \\tilde{} t_{N-k}$\n",
    "\n",
    "\n",
    "**One-way ANOVA: Pairs of means**  \n",
    "Comparing all $\\tfrac{k(k-1)}{2}$ pairs of treatments  \n",
    "q > t at any fixed $\\alpha$ and degrees of freedom df, intervals are wider to compensate for the fact that we are making simultaneous (aka joint) comparisons (multiplicity correction)  \n",
    "$((\\hat\\mu_i - \\hat\\mu_j) \\pm q_{\\alpha, k, N-k} \\sqrt{\\tfrac{\\hat\\sigma^2}{2} (\\tfrac{1}{n_i} + \\tfrac{1}{n_j})}) = ((\\hat\\mu_i - \\hat\\mu_j) \\pm q_{\\alpha, k, N-k} \\text{s.e.}((\\hat\\mu_i - \\hat\\mu_j)))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLR (w/ intercept), k = p + 1**\n",
    "- we are now dealing with vectors/matrices, not scalars  \n",
    "\n",
    "$\\bf\\hat\\beta_i$  \n",
    "$\\hat\\beta_i$ is a linear combination of $ \\{Y_1, Y_2, ..., Y_n\\}$  \n",
    "Assumption $\\hat\\epsilon_i \\tilde{} \\epsilon_i \\tilde{} N(0, \\sigma^2) $  \n",
    "Then $\\hat\\beta_i \\tilde{} N(\\beta, \\Sigma)$  \n",
    "But since we do not know $\\Sigma$, substitute with $\\hat\\sigma^2$  \n",
    "$\\hat\\sigma^2 \\tilde{} \\chi_{n-p-1}^2$  \n",
    "So $\\tfrac{\\hat\\beta_i - \\beta_i}{\\text{ s.e.} (\\hat\\beta_i)} \\tilde{} t_{n-k}$ and thus Confidence Interval for $\\hat\\beta_1$ =\n",
    "$(\\hat\\beta_i \\pm t_{\\tfrac{\\alpha}{2},n-p-1} \\text{ s.e.} (\\hat\\beta_i))$\n",
    "  \n",
    "  \n",
    "\n",
    "$\\bf\\hat y | x^*$  \n",
    "- note: $\\hat y = \\mathbf{x^*}^\\intercal \\hat\\beta$\n",
    "\n",
    "**Confidence Intervals for Regression Line** - uncertainty due to estimation of coefficients  \n",
    "(1-$\\alpha$)% Confidence interval for the regression line (or mean respone) for __one__ instance of predicting variables x*   \n",
    "$= (\\hat y|x^* \\pm t_{\\tfrac{\\alpha}{2}, n-p-1} \\sqrt{\\hat\\sigma^2 \\mathbf{x^*}^\\intercal (\\mathbf{X^\\intercal X})^{-1}\\mathbf{x^*}})$   \n",
    "\n",
    "(1-$\\alpha$)% Confidence interval for the regression line (or mean respone) for __all__ possible instances of predicting variables x\\*    \n",
    "The t critical point is replaced with the critical point based on the f-distribution which is meant to correct for the simultaneous inference across all x*s.  \n",
    "$= (\\hat y|x^* \\pm \\sqrt{(p+1) F_{\\alpha, p+1, n-p-1}} \\sqrt{\\hat\\sigma^2 \\mathbf{x^*}^\\intercal (\\mathbf{X^\\intercal X})^{-1}\\mathbf{x^*}})$ \n",
    "\n",
    "**Prediction Intervals for Regression Line** - uncertainty due to estimation of coefficients, uncertainty due to new observations  \n",
    "(1-$\\alpha$)% Prediction interval for the regression line (or mean respone) for __one future__ instance of response variable y\\* (at x\\*) \n",
    "$= (\\hat y|x^* \\pm t_{\\tfrac{\\alpha}{2}, n-p-1} \\sqrt{1 + \\hat\\sigma^2 \\mathbf{x^*}^\\intercal (\\mathbf{X^\\intercal X})^{-1}\\mathbf{x^*}})$  \n",
    "\n",
    "(1-$\\alpha$)% Prediction interval for the regression line (or mean respone) for __m future__ instances of response variables y\\* (at x\\*)    \n",
    "The t critical point is replaced with the critical point based on the f-distribution which is meant to correct for the simultaneous inference across all x*s.  \n",
    "$= (\\hat y|x^* \\pm \\sqrt{m F_{\\alpha, m, n-p-1}} \\sqrt{1 + \\hat\\sigma^2 \\mathbf{x^*}^\\intercal (\\mathbf{X^\\intercal X})^{-1}\\mathbf{x^*}})$ \n",
    "\n",
    "\n",
    "**Summary**\n",
    "Something is normally distributed. We may not know its true $\\sigma^2$ so must use $\\hat\\sigma^2$ (which is chi-squared distributed). That someting now becomes t-distributed, so it's confidence interval uses t quantile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Variance Estimator (of any RV: response, error etc):**  \n",
    "Assume $Z_1, Z_2, ..., Z_n \\tilde{} N(\\mu, \\sigma^2)$  \n",
    "$s^2 = \\tfrac{\\sum(Z_i - \\bar Z)}{n-1}$, where $\\bar Z = \\tfrac{\\sum Z_i}{n}$  \n",
    "$\\tfrac{(n-1)s^2}{\\sigma^2} \\tilde{} \\chi_{n-1}^2$  \n",
    "Loosing 1 degree of freedom when substituting $\\mu$ with $\\bar Z$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLR/MLR Model Assessment\n",
    "Things to evaluate for 1 model (or compare between 2 models):\n",
    "1. Prediction/explanatory power: R-squared / Adjusted R-squared (for comparison) - if too high => may be overfitting data, cross-validation can tell us more about prediction\n",
    "2. Goodness-of-fit: (regular or standardized) residual analysis done to assess (SLR or MLR, respectively) assumptions. Dr Serban: need to perform the assessment of the assumptions for goodness of fit. ~~overall F-test statistic p-value, p-values on predictors~~\n",
    "3. Mean Square Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Accuracy\n",
    "In real life we most often don't have observed values right away to evaluate out predictions. But if we do, here are some measures:  \n",
    "\n",
    "$Y_i$ = observed value  \n",
    "$Y_{i}^*$ = predicted value  \n",
    "$\\bar Y$ = mean of observed values used to test prediction      \n",
    "imdb.pred = predicted values  \n",
    "nimdb = observed values, used to test prediction  \n",
    "\n",
    "Mean Squared Prediction Error (MSPE) = $\\large \\tfrac{\\sum_{i=1}^{n}(Y_i - Y_{i}^*)^2}{n}$ = mean((imdb.pred-nimdb)^2)  \n",
    "    - OK for evaluating prediction accuracy of a linear regression  \n",
    "    - depends on scale, susceptible to outliers\n",
    "Mean Absolute Prediction Error (MAE) =  $\\large \\tfrac{\\sum_{i=1}^{n}|Y_i - Y_{i}^*|}{n}$ = mean(abs(imdb.pred-nimdb))  \n",
    "     - NOT OK for evaluating prediction accuracy of a linear regression  \n",
    "     - depends on scale, not susceptile to outliers\n",
    "Mean Absolute Percentage Error (MAPE) = $\\large \\tfrac{\\sum_{i=1}^{n} \\tfrac{|Y_i - Y_{i}^*|}{Y_i}}{n}$ = mean(abs(imdb.pred-nimdb)/nimdb)  \n",
    "     - NOT OK for evaluating prediction accuracy of a linear regression\n",
    "     - does not depend on scale, robust to outliers\n",
    "Precision Measure (PM) =  $\\large \\sum_{i=1}^{n} \\tfrac{(Y_i - Y_{i}^*)^2}{(Y_i - \\bar Y)^2} = \\tfrac{\\text{variability in prediction}}{\\text{variability in new data}}$ = sum((imdb.pred-nimdb)^2)/(nimdb-mean(nimdb))^2)  \n",
    "    - OK for evaluating prediction accuracy of a linear regression, best measure so far for lm\n",
    "    - similar to R^2 of a regression\n",
    "    - does not depend on scale\n",
    "    - PM -> 0 means better prediction\n",
    "    \n",
    "    \n",
    "Last step: check whether predicted responses fall within prediction interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-square test - \"goodness-of-fit\"\n",
    "* related: see testing the difference in two population proportions using Z test stastic (prop.test() i think)\n",
    "\n",
    "\n",
    "Penn State:  \n",
    "Example, 2 categories (can be extended to k categories): Suppose the Penn State student population is 60% female and 40% male. Then, if a sample of 100 students yields 53 females and 47 males, can we conclude that the sample is (random and) representative of the population? That is, how \"good\" do the data \"fit\" the probability model  \n",
    "$H_0 : p_F =0.60$  \n",
    "$H_A : p_F \\ne 0.60$  \n",
    "   \n",
    "$Q_1=\\frac{(53-60)^2}{60}+\\frac{(47-40)^2}{40}=2.04$  \n",
    "Reject $H_0$ if $Q_1 \\ge \\chi_{0.05, 1}^{2}(=3.84)$  \n",
    "\n",
    "\n",
    "\n",
    "## Chi-Square Test of Independence of Two Categorical/Qualitative Variables\n",
    "Testing the independence of two categorical variables?\n",
    "Going forward, keep in mind that this Chi-square test, when significant, only provides statistical evidence of an association or relationship between the two categorical variables.  Do NOT confuse this result with correlation which refers to a linear relationship.  \n",
    "\n",
    "chisq.test(rtdirector,awards)  \n",
    "Pearson's Chi-squared test  \n",
    "data: rtdirector and awards  \n",
    "X-squared = 26.192, df = 4, p-value = 2.895e-05  \n",
    "\n",
    "$H_0$ means rtdirector and awards are uncorrelated  \n",
    "$H_1$ means they correlated  \n",
    "Look at p-value to determine: p-value < alpha (=0.05), so the variables are correlated.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review formulas\n",
    "\n",
    "**Population Parameters**  \n",
    "population mean $\\mu = \\tfrac{\\sum x_i}{N}$  \n",
    "population variance $\\sigma^2 = \\tfrac{\\sum (x_i -\\mu)^2}{N}$\n",
    "\n",
    "**Sample Statistics**  \n",
    "sample mean $\\hat\\mu = \\bar x = \\tfrac{\\sum x_i}{N}$  \n",
    "biased sample variance $ s_{n}^2 =  \\tfrac{\\sum (x_i -\\bar x)^2}{n} $  \n",
    "unbiased sample variance $\\hat \\sigma^2 = s^2 =  \\tfrac{\\sum (x_i -\\bar x)^2}{n-1} $  \n",
    "Relationship between unbiased and biased sample variance $\\hat \\sigma^2 = (\\tfrac{n}{n-1}) s_{n}^2$ \n",
    "\n",
    "\n",
    "*A different case (note the different denominator in $\\hat\\sigma^2$):*  \n",
    "$\\hat \\sigma^2 = \\tfrac{(x_i - \\mu)^2}{n}$ , where $\\mu = \\tfrac{\\sum x_i}{N}$.  But $\\mu$ is often unknown, so use $\\bar x$ instead of $\\mu$. This becomes  $\\bar s^2 = \\tfrac{(x_i - \\bar x)^2}{n}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Linear Regression (Simple Linear Regresion, Multiple Linear Regression) is a special case of Generalized Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dr Serban's diction\n",
    "\"Setting\" in estimation vs prediction: instead of \"setting\", think \"observation\" (aka data point, aka row in dataframe)  \n",
    "\"Confounding\" and \"controlling\" variables are getting mixed up, but they are different things - we want controlling vars in the model, but not confounding (i think that is correct??)  \n",
    "\"Inverse\" is accidentally referred to as \"indirect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "Outlier - any point that is far from the majority of the data (x's and/or y)\n",
    "- Leverage point - data point far from the mean of x\n",
    "- Influential point - data point far from the mean of both x's and y\n",
    "    \n",
    "Outliers can be valid (perform analysis with and without them and look at differences) or errors in data entry/recording (need to be discarded)\n",
    "\n",
    "### Checking for outliers\n",
    "**Standardized residuals**  \n",
    "$\\large r_i ^* = \\tfrac{y_i - \\hat y_i}{\\sqrt{\\text{MSE}}}$   \n",
    "*Rule of thumb:*  \n",
    "- if $\\large |r_i ^*|$ > 1, then \"large\" outlier,   \n",
    "- if $\\large |r_i ^*|$ > 2, then \"extremely large\"  \n",
    "\n",
    "**Cook's distance**  \n",
    "Measures how much all the values in the regression model change when the ith observation is removed.  \n",
    "Calculate Cook's distance $D_i$ for each observation:  \n",
    "$\\large D_i = \\tfrac{(\\hat Y_{(i)} - \\hat Y)^\\intercal (\\hat Y_{(i)} - \\hat Y)}{q \\hat\\sigma^2}$,  \n",
    "where $\\hat Y_{(i)}$ is the model __without__ the i-th observation, and $\\hat Y$ are the fitted values from the model __with__ the i-th observation (aka all observations included)\n",
    "  \n",
    "*Rule of thumb:*  \n",
    "$D_i > \\tfrac{4}{n}$ or $D_i > 1$ or any \"large\" $D_i$ should be investigated.\n",
    "\n",
    "\n",
    "\n",
    "## Multicollinearity\n",
    "\n",
    "Multicollinearity (perfect collinearity, near collinearity) results in very large values of $\\mathbf{X^\\intercal X}$, which results in very large standard error/variance/intervals.\n",
    "\n",
    "**Variance Inflation Factor VIF**  \n",
    "VIF measures the proportional increase in the variance of $\\hat \\beta_j$ compared to what it would have been if the predicting variables had been completely uncorrelated.  \n",
    "What want to see is that the variance of $\\hat \\beta_j$ is not significantly larger when we have correlation among the predictive variables versus when we don't have correlation among the predictive variables, which means that multicollinearity will not cause a problem in the regression. So, we will compute VIF for every single predicting variables. If this condition holds for all the predicting variables, it means that the co-estimated coefficients are not likely to be unstable, so collinearity is not a problem. Again, it could be that the predicting variables to be correlated, but it doesn't necessarily mean that that will lead to a problem in the stability of the estimated regression coefficients.\n",
    "\n",
    "Calculate VIF for each predicting variable:  \n",
    "$\\large VIF_{j} = \\tfrac{1}{1 - R_{j}^2}$,  \n",
    "where $R_{j}^2$ is the coefficient of variation of the regression of the variable $X_j$ on all other predicting variables.\n",
    "\n",
    "*Rule of thumb:*  \n",
    "Collinearity is NOT present if  \n",
    "$\\large VIF_{j}< max(10, \\tfrac{1}{1 - R_{model}^2})$,  \n",
    "where $R_{model}^2$ is the coefficient of variation of the regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "https://linareskevin.wordpress.com/2015/09/17/linear-regression-equation-in-latex-using-texmaths-under-libreoffice/  \n",
    "\n",
    "Here is the sample mean:\n",
    "\\begin{document}\n",
    "\n",
    "\\begin{equation}\n",
    "\\bar{y} = \\frac{1}{n}\\sum_{i=1}^n y_i\n",
    "\\end{equation}\n",
    "\n",
    "Here is the sample variance:\n",
    "\\begin{equation}\n",
    "\\sigma^2 = \\frac{\\sum\\limits_{i=1}^{n}(y_i – \\bar{y})^2} {n – 1}\n",
    "\\end{equation}\n",
    "\n",
    "Here is the sample standard deviation:\n",
    "\\begin{equation}\n",
    "\\sigma = \\sqrt\\frac{\\sum\\limits_{i=1}^{n}(y_i – \\bar{y})^2} {n – 1}\n",
    "\\end{equation}\n",
    "Regression Function OLS\n",
    "\\begin{document}\n",
    "\n",
    "Population regression line:\n",
    "\\begin{equation}\n",
    "Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i\n",
    "\\end{equation}\n",
    "\n",
    "Sample regression line:\n",
    "\\begin{equation}\n",
    "\\hat{Y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_i + \\hat{\\epsilon}_i\n",
    "\\end{equation}\n",
    "\n",
    "Sample slope:\n",
    "\\begin{equation}\n",
    "\\hat{\\beta}_1 = \\frac{\\sum(X_i – \\bar{X}) (Y_i – \\bar{Y})} {\\sum(X_i – \\bar{X})^2}\n",
    "\\end{equation}\n",
    "\n",
    "Sample intercept:\n",
    "\\begin{equation}\n",
    "\\hat{\\beta}_0 = \\bar{Y} – \\hat{\\beta}_1 \\bar{X}\n",
    "\\end{equation}\n",
    "\n",
    "Conditional Variance:\n",
    "\\begin{equation}\n",
    "\\hat{\\sigma}^2 = \\frac{\\sum{\\hat{\\epsilon}}^2_i} {n – 2} = \\frac{\\sum(Y_i – \\hat{Y}_i)^2} {n – 2}\n",
    "\\end{equation}\n",
    "\n",
    "Conditional Standard Deviation:\n",
    "\\begin{equation}\n",
    "\\hat{\\sigma} = \\sqrt\\frac{\\sum(Y_i – \\hat{Y}_i)^2} {n – 2}\n",
    "\\end{equation}\n",
    "\n",
    "Sample slope standard error:\n",
    "\\begin{equation}\n",
    "\\hat{\\sigma}{_\\hat{\\beta_{1}}} = \\frac{\\hat{\\sigma}} {\\sqrt{\\sum(X_i – \\bar{X})^2}}\n",
    "\\end{equation}\n",
    "\n",
    "Sample intercept standard error:\n",
    "\\begin{equation}\n",
    "\\hat{\\sigma}{_\\hat{\\beta_{0}}} = \\hat{\\sigma} \\sqrt\\frac{\\sum(X_i)^2} {n\\sum(X_i – \\bar{X})^2}\n",
    "\\end{equation}\n",
    "\n",
    "\\end{document}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](logisticVStraditional.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ spending >> 200: the probability of liking the new logo is so high that an additional point on the spending, adds little to the probability of liking the logo. Summary: the probability curve, as a function of spending, levels off for high values of spending, WHEN SPENDING INCREASES.    \n",
    "@ spending = 200: each additional dollar in the spending is associated with the fixed constant increase in the probability of liking the new logo.  \n",
    "@ spending << 200: the probability of liking the logo is so low, that one dollar lower on the spending subtracts little from the probability of liking the logo. Summary: he probability curve as a function of spending levels off for low values of spending, WHEN SPENDING DECREASES.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "response Y=0 or failure, Y=1 or success (though \"success\" does not necessarily mean desirable results)  \n",
    "**linear model with p predictors and intercept:**  $p = P(Y=1 | x_1, ..., x_p)$ is the probability of success given predictors    \n",
    "**(nonlinear) link functions**\n",
    "link function $g(p) = \\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p$ + <s> epsilon </s>   \n",
    "logit(p) aka log odds ratio or log odds of success $log(\\tfrac{p}{1-p}) = \\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p$  \n",
    "rewritten as $\\tfrac{p}{1-p} = e^{\\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p}$ => $p = \\tfrac{e^{\\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p}}{1+e^{\\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p}}$\n",
    " \n",
    "\n",
    "Logistic regression, with repeated trials: $Y_i \\tilde{} $ Binomial($n_i, p_i$) with $n_i$>1  \n",
    "Logistic regression, without repeated trials: $Y_i \\tilde{} $ Binomial($n_i, p_i$) aka Bernoulli($p_i$)  \n",
    "- cannot perform calculation of residuals, hence cannot perform residual analysis for GoF.\n",
    "- if all predictors are categorical, we can aggregate the data, thus allowing to find a subset of distinct (unique) combinations of predicting variables (i.e. $n_i > 1$).\n",
    "\n",
    "\n",
    "\n",
    "### Model Assumptions  \n",
    "##### Linearity Assumption - different than SLR/MLR\n",
    "Linear relationship between predicting variables $x_1, ..., x_p$ and link function g, i.e. log odds success = $log(\\tfrac{p}{1-p})$  \n",
    "    - Plot: Predictors vs Residuals  \n",
    "    - Plot: Predictors vs Logit of success rate  \n",
    "##### Independence Assumption - different than SLR/MLR\n",
    "$Y_1, ..., Y_n$ are independent RV  \n",
    "    - Plot: Predictors vs Residuals - cannot check independence, settle for uncorrelated errors\n",
    "\n",
    "##### Link function - specific to logistic regression\n",
    "Though logit function is most commonly used, sometimes the other ones may fit the data better. \n",
    "- most common link function g: logit(p)=$log(\\tfrac{p}{1-p}) = log(\\tfrac{\\text{probability of success}}{\\text{probability of failure}}) = log(\\text{odds ratio}) = log(\\text{odds of success})$  \n",
    "    - advantages over the other 2 functions:\n",
    "        - logit is a canonical link function, i.e. parameter estimates obtained under it are fully efficient and statistical tests on those parameters are better behaved for small samples\n",
    "        - possibility of interpreting regression coefficient as log odds ratio or exp(regression coefficients) as odds ratio\n",
    "- probit: inverse of cdf of std. normal, fits data with least heavy tails compared to other 2 link functions, so works well when probabilities are concentrated within a small range.\n",
    "- complimentary log log.\n",
    "##### Normality Assumption - CANNOT HAVE, response is binomial, HOWEVER need to check normality of residuals (Pearson residuals or deviance residuals - should follow approximately N(0,1) if to the model is a good fit)\n",
    "- Check that residuals are **approximately** standard normal for GoF\n",
    "        - Plot: Q-Q plot\n",
    "        - Plot: Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note! Logistic model has no error term!!  \n",
    "**note! logistic regression/poisson regression relies on large sample size when testing (subsets) of coefficients, testing for statistical signficance on individual coefficients**   \n",
    "note! careful with words like \"response\" and \"significant\". In SLR/MLR - response is the continuous variable we are modeling, in logistic regression - response is a binary variable, but we are modeling the probability of binary variable = \"success\", or 1 (doesn't necessarily mean that the outcome is desirable), which sometimes gets mislabled as response. \"Significant\" may mean statistically significant (e.g. the p-value is low), or \"significant\" may mean visible/large/enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions\n",
    "note!: In SLR/MLR we had an error term so we were able to distinguish between a response's confidence intervals and prediction intervals. In Poisson/logistic regression we have no error term! So we cannot really make that distinction. We do distinguish between in-sample predictions (using observations from training data to make a prediction), and out-of-sample predictions (using brand new, unused observations). We do still distinguish between a response interval and a coefficient interval though  \n",
    "\n",
    " $\\hat\\beta_j$ is approximately N($\\beta, V$)  \n",
    "(1-$\\alpha$)% Approximate Conf Interval (Wald test): $\\hat\\beta_j \\pm z_{\\tfrac{\\alpha}{2}} \\sqrt{V(\\hat\\beta_j)}$, as compared to SLR/MLR t-distribution (when variance unknown), or z-distribution (when variance is known)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saturated model - when we estimate response, i.e. the probability of success, disregarding the predictors, that is we assume that estimated expected response is the observed response (in simple english: there is no model)  \n",
    "Fitted model - when we estimate response, i.e. the probability of success, using the predictors. \n",
    "\n",
    "\n",
    "note ! [Residual] Deviance $\\ne$ deviance residual $d_i$   \n",
    "note ! [Residual] Deviance = $\\sum_{i=1}^{n} d_i^2$, sometimes it is used to calculate the test statistic, sometimes it is the test statistic. \n",
    "\n",
    "Pearson residuals $r_i$ = *std.zed (depends on definition) difference between observed response and expected/fitted response (cz observed and fitted responses have different variance)*  \n",
    "Deviance residuals $d_i$ = *Signed square root of the log-likelihood evaluated at saturated model vs fitted model*  \n",
    "Deviance test stat (for GoF)  $\\sum_{i=1}^{n} d_i^2$ = *sum of deviance residuals*    \n",
    "OR Deviance test stat (for GoF)  $\\sum_{i=1}^{n} r_i^2$= *sum of pearson residuals*    \n",
    "Deviance test stat (for all coefficients) = Null deviance - $\\sum_{i=1}^{n} d_i^2$  \n",
    "Deviance test stat (for subset of coefficients) = Deviance of reduced model - Deviance of full model  = $\\sum_{i=1}^{n} d_{i, reduced}^2 - \\sum_{i=1}^{n} d_{i, full}^2$  \n",
    "Null deviance = hows how well the response variable is predicted by a model that includes only the intercept (grand mean).\n",
    "\n",
    "Full model = model with all predictors  \n",
    "Reduced model = model with a subset of predictors removed (for testing on that subset of coefficients)  \n",
    "Null model = special case of reduced model, only intercept in the model  \n",
    "\n",
    "\n",
    "- deviance residuals `deviance_res = residuals(someLogisticModel,type=\"deviance\")`  \n",
    "- pearson residuals `pearson_res = residuals(someLogisticModel,type=\"pearson\")`  \n",
    "- Deviance using deviance residuals aka 'Residual deviance' aka  difference between the model deviance and null deviance (per class TA) `deviance_using_deviance_res  =  sum(deviance_res^2)` (also `deviance(someLogisticModel) or someLogisticModel$deviance`)  \n",
    "- Deviance using pearson residuals `deviance_using_pearson_res = sum(pearson_res^2)`  \n",
    "- Null deviance `null_deviance = someLogisticModel$null.deviance`  \n",
    "\n",
    "**For test on ALL regression coefficients (notice it's NOT an F test, it's Deviance test)**:  \n",
    "Model is $ logit \\ p(x_1,...,x_p, z_1,...,z_p) = \\beta_0 + (\\beta_1 x_1+ \\beta_2 x_2 + ... + \\beta_{p} x_p)$  \n",
    "$H_0: \\beta_1 = \\beta_2 = ... = \\beta_p = 0$   \n",
    "$H_1$: at least one $\\beta_i \\ne 0$  \n",
    "P-value = P($\\chi_{p}^2 > \\text{Deviance}$), reject $H_0$ if p-val < $\\alpha$     \n",
    "- `null_deviance` $-$ Residual deviance `deviance_using_deviance_res`= `deviance_test_stat`       \n",
    "- `null_deviance`  $\\tilde{} \\ \\chi_{n-1}^2$, Residual deviance `deviance_using_deviance_res` $\\tilde{} \\ \\chi_{n-p-1}^2$,  `deviance_test_stat` $\\tilde{} \\ \\chi_{p}^2$          \n",
    "- Compute p-value for Deviance test statistic: `1 - pchisq(deviance_test_stat, df = p predictors)`  \n",
    "\n",
    "\n",
    "\n",
    "**For test on SUBSET of regression coefficients(notice it's NOT an F test, it's Deviance test):**   \n",
    "Full model is $ logit \\ p(x_1,...,x_p, z_1,...,z_p) = \\beta_0 + (\\beta_1 x_1+ \\beta_2 x_2 + ... + \\beta_{p} x_p) + (\\alpha_1 z_1+ \\alpha_2 z_2 + ... + \\alpha_{q} z_q)$  \n",
    "Reduced model is $ logit \\ p(x_1,...,x_p, z_1,...,z_p) = \\beta_0 + (\\beta_1 x_1+ \\beta_2 x_2 + ... + \\beta_{p} x_p)$  \n",
    "$H_0: \\alpha_1 = \\alpha_2 = ... = \\alpha_q = 0$   \n",
    "$H_1$: at least one $\\alpha_i \\ne 0$   \n",
    "P-value = P($\\chi_{q}^2 > \\text{Deviance}$), reject $H_0$ if p-val < $\\alpha$      \n",
    "- Deviance of reduced model $-$ Deviance of the full model= `deviance_test_stat`    \n",
    "- Deviance test statistic $\\tilde{} \\ \\chi_{q}^2$  \n",
    "- Compute p-value for Deviance test statistic: `1 - pchisq(deviance_test_stat, df= q predictors in subset)`  \n",
    " \n",
    "**Somewhat related: Goodness of Fit: Hypothesis Testing (use Pearson or Deviance residuals for this Deviance test)**  \n",
    "$H_0$: model fits data  \n",
    "$H_1$: model does NOT fit data    \n",
    "Deviance test stat (sum of deviance residuals) = $\\sum_{i=1}^{n} d_i^2 \\tilde{} \\chi_{n-p-1}^{2}$   \n",
    "OR Deviance test stat (sum of pearson residuals) = $\\sum_{i=1}^{n} r_i^2 \\tilde{} \\chi_{n-p-1}^{2}$   \n",
    "P-value = P($\\chi_{n-p-1}^2 > \\text{Deviance}$), `1 - pchisq(deviance_using_deviance_res, df = n-p-1)`   \n",
    "OR P-value P($\\chi_{n-p-1}^2 > \\text{Deviance}$), `1 - pchisq(deviance_using_pearson_res, df = n-p-1)`    \n",
    "Reject $H_0$ if p-val < $\\alpha$  \n",
    "THIS IS RARE WHEN WANT LARGE P-VALUES (SO THAT WE DO NOT REJECT $H_0$, MEANING MODEL FITS DATA)  \n",
    "\n",
    "**For test of statistical significance on one predictor, given all other predictors in model: Wald test**  \n",
    "**See section Hypothesis testing using z test statistic for all 3 (left-tailed, 2-tailed, right-tailed)**  \n",
    "$H_0: \\beta_i = 0$  \n",
    "$H_1: \\beta_i \\ne 0$  \n",
    "Test stat:  $\\tfrac{\\hat\\beta_j - 0}{\\text{std error}(\\hat\\beta_j)}$, reject $H_0$ is |z-value| > $z_{\\tfrac{\\alpha}{2}}$   \n",
    "P-value: 2 * P(Z $\\ge$ |z-value|), reject $H_0$ if p-val < $\\alpha$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](link_inverses.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation (recap from ISYE 6501)\n",
    "1. Random subsampling (in 6501 there was train, test, AND validation)  \n",
    "`for i = 1 to desired_repetitions:\n",
    "    randomly split data into training set and testing set  \n",
    "    train, test and calculate classification error  \n",
    "    total_classification_error += classification_error\n",
    "    i++\n",
    "return mean(classification_error)`\n",
    "    \n",
    "2. k-fold cross-validation  \n",
    "`divide data into k chunks  \n",
    "for i = 1 to k:  \n",
    "    train model on all data except k subset\n",
    "    test on k subset and calculate classification error  \n",
    "    total_classification_error += classification_error\n",
    "    i++  \n",
    "return mean(classification_error)`\n",
    "\n",
    "3. leave-one-out cross-validation (n-fold cross-validation)\n",
    "    - k is equal to n, number of observations\n",
    "    \n",
    " \n",
    "\n",
    "### Predictive Power or Classification Error via Cross-Validation (at Different Thresholds)\n",
    "\n",
    "For logistic regression, we need to pick a threshold t above which the fitted response > t gets rounded to 1, fitted response < t gets rounded to 0. Plot different tresholds t against their [cross-validated] classification errors at, so-called \"elbow diagram\".   \n",
    "\n",
    "At different thresholds:  \n",
    "`For t=0, 0.1, 0.2, ..., 0.9, 1 # do not make this a loop, so much harder to debug and understand` \n",
    "- compute the cost function:  \n",
    "    `cost_t = function(y, pi){\n",
    "     ypred=rep(0,length(y))\n",
    "     ypred[pi>t] = 1\n",
    "     err = mean(abs(y-ypred)) # MAE\n",
    "     return(err) # MAE\n",
    "    }`\n",
    "- compute classification error for k-fold cross-validation (k is fixed here):  \n",
    "`cv.err_t = cv.glm(obdata.fr,model,cost=cost_t, K=k)$delta[1] #cv.err_t is the mean of all MAEs in this case`  \n",
    "`t = t + 1/10 # can be 1/any_integer`\n",
    "\n",
    "Predictive accuracy (which is inversely proportional to classification error) - is comparing **classification error from cross-validation (i think it's the average of all MAEs) either at different thesholds (as above)** or for different models altogether.  \n",
    "\n",
    "- DO NOT FORGET TO COMPARE CLASSIFICATION ERROR OF A MODEL (I'm guessing at the threshold we picked) TO A CLASSIFICATION ERROR WHEN ALL RESPONSES ARE PREDICTED TO BE 1 OR 0, I.E. EQUAL TO A VALUE OF THE LARGEST CATEGORY. (I think this is equivalent to looking at cv.err_t when cost_0(y, pi) or cost_1(y, pi))  \n",
    "- If the classification error above 0.5 threshold is constant, bad news: our model has same or less predicting power than no model  \n",
    "- `cv.err = c(cv.err0.35,cv.err0.35,cv.err0.4,cv.err0.45,cv.err0.5,cv.err0.55,cv.err0.6,cv.err0.65)`   \n",
    " `plot(c(0.3, 0.35,0.4,0.45,0.5,0.55,0.6,0.65),cv.err,\n",
    "     type=\"l\",lwd=3,xlab=\"Threshold\",ylab=\"CV Classification Error\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Classification Errors at Different Thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![.](elbow_diagram_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE\n",
    "Maximum Likelihood Estimation (i.e. approach) or Maximum Likelihood Estimator (i.e. estimators obtained from the approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note! : Poisson, just like Logistic regression, has no error term   \n",
    "note! : Poisson, just like Logistic regression, relies on large sample size when testing (subsets) of coefficients, testing for statistical signficance on individual coefficients   \n",
    "note! : Most importantly for SLR/MLR under the assumption of normality, the statistical inference relies on the distribution that applies under both small and large samples. On the other hand, for logistic regression, the statistical inference based on the normal distribution applies only under large sample data. \n",
    "\n",
    "note! : when the the number of counts per unit is small (i.e. a small rate, i.e. small response), the Poisson model will fit better than then SLR/MLR, because SLR/MLR assumes constant variance and this is not the case in Poisson. Notice it's the fit that's better, not statistical inference on the results. If we have larger counts per response, we can get away with SLR/MLR due to normality approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model  \n",
    "Data: {$(x_{11}, ..., x_{1p}), Y_1$}, ... ,{$(x_{n1}, ..., x_{np}), Y_n$}, where $Y_i$ is counts per unit  \n",
    "Model: log(E (y | $x_1, ..., x_p$) = $\\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p$  OR E (y | $x_1, ..., x_p$) = $e^{\\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p}$  \n",
    "When the \"per\" unit is not the same for all observations, cannot just scale response by dividing all counts by all units, use `glm(..., offset(some_units))` because R expects discrete counts, and division will cause non-discrete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In poisson: E(Y) = V(Y) = $\\lambda$ = expected rate\n",
    "\n",
    "Using SLR with log(response) will result in violations of the assumption of constant variance. We are to use Poisson Regression instead when data has small counts per unit. When data has large counts per unit, SLR could be used with transformed response (for stabilitation: $\\sqrt{\\mu + \\tfrac{3}{8}}$) instead of log-transformed response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLR w/ log(response)   |Poisson Regression\n",
    "---|---\n",
    "Expected(log(y) $|$ $x_1, ..., x_p$) = $\\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p$ | log(Expected (y $|$ $x_1, ..., x_p$) = $\\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p$ <br>OR</br> <br>  Expected (y $|$ $x_1, ..., x_p)$ = $e^{\\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p}$</br> \n",
    "Variance(log(y) $|$ $x_1, ..., x_p$) = constant| log(Variance (y $|$ $x_1, ..., x_p))$ = $\\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p$ <br>OR</br> <br>  Variance (y $|$ $x_1, ..., x_p)$ = $e^{\\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p}$</br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Logistic regression                          |Poisson regression                          |    \n",
    "|---|---|\n",
    "|$\\beta_i$ = log of odds ratio = log of ratio of odds       |$\\beta_i$ = log of rates ratio = log of ratio of rates      |\n",
    "|$p(x_1, ..., x_p) = P(Y=1 \\ x_1, ..., x_p) = \\large \\tfrac{e^{\\beta_1 x_1 + ...+ \\beta_p x_p}}{1+e^{\\beta_1 x_1 + ...+ \\beta_p x_p}}$| $log(\\lambda_i(x)) = log(E(Y | x_1, ...,x_p)) = \\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p$ <br>OR</br> <br> $\\lambda_i(x) = E(Y | x_1, ...,x_p) = \\large e^{\\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p}$</br>|\n",
    "|link functions: logit, probit, complimentary log-log|link functions: log|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Assumptions\n",
    "##### Linearity Assumption - different than SLR/MLR\n",
    "Linear relationship between predicting variables $x_1, ..., x_p$ and log(Expected (y $|$ $x_1, ..., x_p$)) aka log($\\lambda(x)$) aka log(response)\n",
    "    - Plot: Predictors vs Residuals  \n",
    "    - Plot: Predictors vs Logit of success rate  \n",
    "##### Independence Assumption - different than SLR/MLR\n",
    "$Y_1, ..., Y_n$ are independent RV  \n",
    "    - Plot: Predictors vs Residuals - cannot check independence, settle for uncorrelated errors\n",
    "\n",
    "##### Variance Assumption\n",
    "Expected (y $|$ $x_1, ..., x_p)$ = Variance (y $|$ $x_1, ..., x_p)$= $e^{\\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p}$\n",
    "##### Normality Assumption - CANNOT HAVE, response is binomial, HOWEVER need to check normality of residuals (Pearson residuals or deviance residuals - should follow approximately N(0,1) if to the model is a good fit)\n",
    "- Check that residuals are **approximately** standard normal for GoF\n",
    "        - Plot: Q-Q plot\n",
    "        - Plot: Histogram\n",
    "        \n",
    "        \n",
    "$Y_i | (x_{i1}, ..., x_{ip}) \\tilde{} Poisson (\\lambda(x_{i1},...,x_{ip}))$  \n",
    "Estimated rates $\\hat \\lambda_i = \\hat \\lambda_i (x_{i1},...,x_{ip}) = e^{\\hat\\beta_0 + \\hat\\beta_1 x_1 + ... + \\hat \\beta_p x_p}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions - see Poisson section\n",
    "\n",
    "**For test on ALL regression coefficients (notice it's NOT an F test, it's Deviance test)**:  \n",
    "[Full] Model  is $ log(E(Y|x_1,...,x_p, z_1,...,z_p)) = \\beta_0 + (\\beta_1 x_1+ \\beta_2 x_2 + ... + \\beta_{p} x_p)$  \n",
    "[Reduced Model is $log(E(Y)) = \\beta_0$]  \n",
    "$H_0: \\beta_1 = \\beta_2 = ... = \\beta_p = 0$   \n",
    "$H_1$: at least one $\\beta_i \\ne 0$  \n",
    "P-value = P($\\chi_{p}^2 > \\text{Deviance}$), reject $H_0$ if p-val < $\\alpha$     \n",
    "- `null_deviance` $-$ Residual deviance `deviance_using_deviance_res`= `deviance_test_stat` = null log-likelihood - full log-likelihood           \n",
    "- `null_deviance`  $\\tilde{} \\ \\chi_{n-1}^2$, Residual deviance `deviance_using_deviance_res` $\\tilde{} \\ \\chi_{n-p-1}^2$,  `deviance_test_stat` $\\tilde{} \\ \\chi_{p}^2$          \n",
    "- Compute p-value for Deviance test statistic: `1 - pchisq(deviance_test_stat, df = p predictors)`  \n",
    "\n",
    "\n",
    "\n",
    "**For test on SUBSET of regression coefficients(notice it's NOT an F test, it's Deviance test):**   \n",
    "Full model is $ log(E(Y|x_1,...,x_p, z_1,...,z_p)) = \\beta_0 + (\\beta_1 x_1+ \\beta_2 x_2 + ... + \\beta_{p} x_p) + (\\alpha_1 z_1+ \\alpha_2 z_2 + ... + \\alpha_{q} z_q)$  \n",
    "Reduced model is $ log (E(x_1,...,x_p, z_1,...,z_p)) = \\beta_0 + (\\beta_1 x_1+ \\beta_2 x_2 + ... + \\beta_{p} x_p)$  \n",
    "$H_0: \\alpha_1 = \\alpha_2 = ... = \\alpha_q = 0$   \n",
    "$H_1$: at least one $\\alpha_i \\ne 0$   \n",
    "P-value = P($\\chi_{q}^2 > \\text{Deviance}$), reject $H_0$ if p-val < $\\alpha$      \n",
    "- Deviance of reduced model $-$ Deviance of the full model= `deviance_test_stat`= reduced log-likelihood - full log-likelihood    \n",
    "- Deviance test statistic $\\tilde{} \\ \\chi_{q}^2$  \n",
    "- Compute p-value for Deviance test statistic: `1 - pchisq(deviance_test_stat, df= q predictors in subset)`  \n",
    "\n",
    "**Somewhat related: Goodness of Fit: Hypothesis Testing (use Pearson or Deviance residuals for this Deviance test)**  \n",
    "$H_0$: model fits data  \n",
    "$H_1$: model does NOT fit data    \n",
    "Deviance test stat (sum of deviance residuals) = $\\sum_{i=1}^{n} d_i^2 \\tilde{} \\chi_{n-p-1}^{2}$   \n",
    "OR Deviance test stat (sum of pearson residuals) = $\\sum_{i=1}^{n} r_i^2 \\tilde{} \\chi_{n-p-1}^{2}$   \n",
    "P-value = P($\\chi_{n-p-1}^2 > \\text{Deviance}$), `1 - pchisq(deviance_using_deviance_res, df = n-p-1)`   \n",
    "OR P-value P($\\chi_{n-p-1}^2 > \\text{Deviance}$), `1 - pchisq(deviance_using_pearson_res, df = n-p-1)`    \n",
    "Reject $H_0$ if p-val < $\\alpha$  \n",
    "THIS IS RARE WHEN WANT LARGE P-VALUES (SO THAT WE DO NOT REJECT $H_0$, MEANING MODEL FITS DATA) \n",
    "\n",
    "\n",
    "**For test of statistical significance on one predictor, given all other predictors in model: Wald test**  \n",
    "**See section Hypothesis testing using z test statistic for all 3 (left-tailed, 2-tailed, right-tailed)**  \n",
    "$H_0: \\beta_i = 0$  \n",
    "$H_1: \\beta_i \\ne 0$  \n",
    "Test stat:  $\\tfrac{\\hat\\beta_j - 0}{\\text{std error}(\\hat\\beta_j)}$, reject $H_0$ is |z-value| > $z_{\\tfrac{\\alpha}{2}}$   \n",
    "P-value: 2 * P(Z $\\ge$ |z-value|), reject $H_0$ if p-val < $\\alpha$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overdispersion in GLM - see Dr Serban notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "# In this class  \n",
    "*SLR/MLR:*  \n",
    "**goodness of fit assessment** means analyzing residuals (from SLR - regular residuals, for MLR's constant variance - standardized [the lecture slides forgot to do that], for MLR's other assumptions - regular) to check if the 4 model assumptions hold,   \n",
    "R-squared is used for **predictive/explanatory power** (though cross-validation will tell us more on predictive power),    \n",
    "**the overall F test, the partial F test, and the individual p-values** of the coefficients is to determine statistical significance of all predictors excluding intercept, of a subset of predictors, and of an individual predictor, respectively;  \n",
    "\n",
    "*Logistic Regression:*    \n",
    "**goodness of fit assessment**  means\n",
    "- analyzing residuals (just deviance) to check if the 3 model assumptions hold (linearity, independence - more like uncorrelated errors, link function), AND checking those residuals are normally distributed (even though it's not in the original assumptions list)   \n",
    "- AND performing hypothesis testing on residuals (both Pearson and deviance), i.e. computing the p-value of the Deviance statistic D (where a LARGE p-value to NOT REJECT H0, meaning model fits data well), \n",
    "\n",
    "\n",
    "**predictive power** means comparison of classification error from cross-validation at different thresholds  \n",
    "\n",
    "*Poisson Regression:*  \n",
    "**goodness of fit assessment**  means\n",
    "- analyzing residuals (just deviance) to check if the model assumptions hold (linearity, independence - more like uncorrelated errors, ??variance assumption),  AND checking those residuals are normally distributed (even though it's not in the original assumptions list)  \n",
    "- AND performing hypothesis testing on residuals (both Pearson and deviance), i.e. computing the p-value of the Deviance statistic D (where a LARGE p-value to NOT REJECT H0, meaning model fits data well),  \n",
    "\n",
    "\n",
    "**predictive power** means  means comparison of classification error from cross-validation at different thresholds \n",
    "\n",
    "*From Avery Scott*  \n",
    "Question on testing subsets of variables and model comparison:\n",
    "- likelihood ratio tests compare models\n",
    "    - Takes the form of partial F-test in multiple linear regression and simple linear regression\n",
    "- Differences of the log of the differences in any generalized linear model\n",
    "   - can compare any models with this concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "We cannot perform variable selection based on the statistical significance of the regression coefficients, statistical significance is only true in the context of that given model. Also, a better model can be found, even if the current one's variables are all statistically significant. It's possible to select a model to include variables that are not statistically significant, even though that model will provide the best prediction, for example, and vice versa.\n",
    "\n",
    "Once the model selection yields a list of variables, re-fit model using glm() (or lm()) with the variables on their original scale\n",
    "- Best Subset (not possible if p is large: $2^p$ subsets to check )\n",
    "- Greedy algorithms (forward stepwise, backward stepwise, forward-backward stepwise)\n",
    "    - Backward and forward stepwise regression will generally provide different sets of selected variables when p, the\n",
    "number of predicting variables, is large. Backward stepwise cannot be performed if p larger than n\n",
    "\n",
    "    - Forward stepwise regression is preferable over backward stepwise regression because it starts with smaller models.\n",
    "- Global algorithms - regularized regression (lasso, ridge (not for selection), elastic net = lasso + ridge)\n",
    "    - Before fitting: Must standardize predicting variables (numerical ones), recommended to standardize response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graphical Definition**  \n",
    "We can create a graphical visualization of bias and variance using a bulls-eye diagram. Imagine that the center of the target is a model that perfectly predicts the correct values. As we move away from the bulls-eye, our predictions get worse and worse. Imagine we can repeat our entire model building process to get a number of separate hits on the target. Each hit represents an individual realization of our model, given the chance variability in the training data we gather. Sometimes we will get a good distribution of training data so we predict very well and we are close to the bulls-eye, while sometimes our training data might be full of outliers or non-standard values resulting in poorer predictions. These different realizations result in a scatter of hits on the target.\n",
    "\n",
    "We can plot four different cases representing combinations of both high and low bias and variance.  \n",
    "(irina: how to remember: p ~ variance, variance ~ 1/bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](bias_variance_tradeoff_edited.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notation\n",
    "\n",
    "Given  \n",
    "S $\\subset \\{1, \\cdots, p\\}$ = a subset indices   \n",
    "{$x_j$ for j $\\in S$} = the subset of predicting vars with indices in S  \n",
    "\n",
    "for p predictor variables there are $2^p$ models to choose from  \n",
    "\n",
    "$\\hat \\beta(S)$ = estimated regression coefficients for the submodel with design matrix $X_s = \\{x_j \\text{ for } j \\in S\\}$ predicting variables  \n",
    "$\\hat Y(S)$ = fitted value for submodel with $\\{x_j \\text{ for } j \\in S\\}$ predicting variables   predicting variables  \n",
    "e.g. regression assuming normality $\\hat Y(S) = X_s  \\ \\hat\\beta(S)$,  \n",
    "This will be referred to as S submodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Risk Estimation (via Training Risk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R(S) = \\tfrac{1}{n} \\sum_{i=1}^{n} E (\\overbrace{\\hat Y_i (S)}^\\text{Prediction} - \\overbrace{Y_{i}^*}^\\text{Future observation})^2 = \\underbrace{\\overbrace{V(Y_{i}^*)}^\\text{Variance of future observation}}_\\text{irreducible error} + \\underbrace{\\overbrace{Bias^2 (\\hat Y_i(S))}^\\text{Bias Squared of prediction} + \\overbrace{V(\\hat Y_i(S)))}^\\text{Variance of prediction}}_\\text{Mean Squared Error, can be controlled}$ = Prediction Risk for a submodel S  \n",
    "\n",
    "- Sometimes, it is possible to find a model with lower MSE than an unbiased model!\n",
    "- It is “generic” in statistics: almost always introducing some bias yields a decrease in MSE.\n",
    "\n",
    "\n",
    "\n",
    "For GLM, Prediction Risk = $- E [\\text{log-likelihood function}]$\n",
    "\n",
    "Cannot obtain prediction risk at the time of prediction because we do not yet have the future observation.  \n",
    "To estimate prediction risk, substitute future observation $Y_{i}^*$ with current observations $Y_i$:  \n",
    "$R_{train}(S) = \\tfrac{1}{n} \\sum_{i=1}^{n} E (\\overbrace{\\hat Y_i (S)}^\\text{Prediction} - \\overbrace{Y_{i}^*   }^\\text{Current observation})^2 =$ upward biased estimate of prediction risk since we used the data to both train the model AND estimate risk (data snooping).  \n",
    "$R_{train}(S)$ increases with the number of predictors p in the model, so **must correct for bias** by penalizing $R_{train}(S)$ so it doesn't automatically prefer a complex model aka a model with more predictors.  \n",
    "Thus,   \n",
    "$\\hat R(S) = R_{train}(S) + \\text{Some Complexity Penalty CP}$: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correcting Training Risk for bias in Linear Models:\n",
    "Given |S| as number of predictors in the model and $\\hat R(S) = R_{train}(S) + \\text{Some Complexity Penalty CP}$:  \n",
    "- using Mallow's CP: $\\hat R(S) = R_{train}(S) + \\large  \\tfrac{2 \\ |S| \\ \\hat\\sigma_{\\text{full model}}^2}{n}$, where  $\\hat\\sigma_{\\text{full model}}^2$ = estimated variance of full model (not always possible to estimate: e.g. when p > n)\n",
    "- using Akaike IC CP:  $\\hat R(S) = R_{train}(S) + \\large  \\tfrac{2 \\ |S| \\ \\sigma_{\\text{full model}}^2}{n}$,  where  $\\sigma_{\\text{full model}}^2$ = true variance of full model, not estimated\n",
    "    - Need to replace $\\sigma_{\\text{full model}}^2$ with $\\hat\\sigma_{\\text{full model}}^2$ or $\\hat\\sigma_{\\text{submodel}}^2 (S)$\n",
    "    - Important! Most software replaces $\\sigma_{\\text{full model}}^2$ with $\\hat\\sigma_{\\text{submodel}}^2 (S)$.\n",
    "    - Akaike Information Criterion is an estimate for the prediction risk.\n",
    "\n",
    "- using Bayesian IC CP: $\\hat R(S) = R_{train}(S) + \\large  \\tfrac{log(n) \\ |S| \\ \\sigma_{\\text{full model}}^2}{n}$\n",
    "    - Need to replace $\\sigma_{\\text{full model}}^2$ with $\\hat\\sigma_{\\text{full model}}^2$ or $\\hat\\sigma_{\\text{submodel}}^2 (S)$\n",
    "    - BIC penalizes complexity more than other approaches => preferred in model selection\n",
    "- Leave-One-Out CV Approximation: $\\hat R_{CV}(S)\\approx R_{train}(S) + \\large \\tfrac{2 \\ |S| \\ \\hat\\sigma_{\\text{submodel}}^2(S)}{n}$. \n",
    "    - Because  $\\hat\\sigma_{\\text{submodel}}^2 (S) \\le \\hat\\sigma_{\\text{full model}}^2$, LOO CV Approximation CP penalizes complexity less than Mallow's CP\n",
    "\n",
    "\n",
    "Leave-One-Out CV (a direct measurement of predictive power):\n",
    "$\\hat R_{CV}(S) = \\tfrac{1}{n} \\sum_{i=1}^{n} (\\hat Y_{(i)} - Y_i)^2$, where $\\hat Y_{(i)}$ is $\\hat Y$ estimated from a model fitted without observation $i$. LOO CV is approximately AIC when $\\sigma^2$ is replaced by $\\hat \\sigma_{\\text{submodel}}^2 (S)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correcting Training Risk for bias in Generalized Linear Models (e.g. in Logistic or Poisson Regression):\n",
    "Training risk $R_{train}(S) $ for a submodel S, fitted response for submodel S $\\hat Y_i (S)$, future observation $Y_i^*$\n",
    "$R_{train}(S) = \\tfrac{1}{n} \\sum_{i=1}^{n} 2 Y_i^* log [\\tfrac{Y_i^*}{\\hat Y_i (S)}] + 2 (n_i - Y_i^*) log [\\tfrac{n_i-Y_i^*}{n_i - \\hat Y_i (S)}]$ = sum of square deviances of submodel S\n",
    "- Akaike Information Criterion CP and Bayesian Information Criterion CP are commonly used for model selection in GLM since they are defined in terms of log-likelihood function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penalizing the [Minimized] Sum of Squared Errors (aka Sum of Least Squares) in Regularized Regression\n",
    "*I think the $\\beta_i$ in my physical notes are meant to be $\\hat \\beta_i$, so I'm fixing this*  \n",
    "$ \\text{min } Q(\\beta_1, ..., \\beta_p) = \\sum_{i=1}^{n} (y_i - \\hat y_i)^2  + \\lambda \\cdot \\text{Some Penalty}(\\hat\\beta_1,...,\\hat\\beta_p)= \\sum_{i=1}^{n} (y_i - (\\hat\\beta_0 + \\hat\\beta_1 x_{i1} + ... + \\hat \\beta_p x_{ip}))^2  + \\lambda \\cdot \\text{Some Penalty}(\\hat\\beta_1,...,\\hat\\beta_p)=$\n",
    "\n",
    "The penalty constant $\\lambda$ in penalized or regularized regression controls the trade-off between lack of fit and model complexity\n",
    "\n",
    "Choices of Penalty: \n",
    "- $L_0$ penalty: $||\\beta||_0 = \\{j: \\hat\\beta_j \\ne 0\\}$, provides best model given a selection criterion, but it requires fitting all possible submodels which may not be possible.\n",
    "- $L_1$ penalty, Lasso: $||\\beta||_1 = \\sum_{j=1}^{p} |\\hat \\beta_j|$, measures sparsity\n",
    "- $L_2$ penalty, Ridge: $||\\beta||_2 =  \\sum_{j=1}^{p} \\hat \\beta_j^2$, easy to implement but it does not do variable selection, does not distinguish between sparse and non-sparse vectors\n",
    "\n",
    "Note! For performing model selection using regularized regression, predicting variables MUST be ~~scaled~~ standardized, response is recommended to be ~~scaled~~ standardized. After selecting the \"best\" model, use the original scale when fitting the selected model for interpretation of the regression coefficients.  \n",
    "Note ! The $L_1$ penalty produces spare estimates, while the $L_2$ penalty does not.\n",
    "\n",
    "$\\tfrac{1}{n} \\sum_{i=1}^{n} x_{ij} = 0, \\ \\ \\ \\  \\tfrac{1}{n} \\sum_{i=1}^{n} x_{ij}^2 = 1$\n",
    "\n",
    "$\\tfrac{1}{n} \\sum_{i=1}^{n} Y_{i} = 0, \\ \\ \\ \\  \\tfrac{1}{n} \\sum_{i=1}^{n} Y_{i}^2 = 1$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note on scaling vs standardization\n",
    "Standardization is transforming your data so it has mean 0 and standard deviation 1, like a standard normal distribution: `x = (x - mean(x)) / sd(x)`. Confusingly enough, `scale()` in R will standardize data for you.  \n",
    "Scaling is transforming your data to a 0-1 range: `x = (x - min(x)) / (max(x) - min(x))`\n",
    "\n",
    "\n",
    "Centering means substacting the mean of the random variable from the variables.  \n",
    "Scaling means dividing variable by its standard deviation.   \n",
    "Combination of the two is called standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Lasso |Ridge |\n",
    "|---|---|\n",
    "|Lasso performs variable selection <br> Does not work when (number of predictors) p > n (number of observations),<br> lasso can only select up to n vars|Ridge does not perform variable selection|\n",
    "|There is NO  closed form regression for estimated regression coefficients, <br>numerical algorithm required|There is a closed form regression for estimated regression coefficients|\n",
    "|Estimated regression coefficients are less efficint than those from OLS:<br> once model is selected using lasso, use OLS to estimate coefficients||\n",
    "|Lasso does not deal with multicollinearity:<br> coefficients on most of the highly collinear predictors will be forced to zero, randomly (i.e. NOT intelligently) <br> Lasso forces some coefficients to be 0|Ridge deals with multicollinearity:<br> a subset of highly collinear predictors with have very small coefficients.<br> Ridge shrinks coefficients towards 0, but does not force them to be 0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Net = Lasso + Ridge\n",
    "$\\sum_{i=1}^{n} (y_i - (\\hat\\beta_0 + \\hat\\beta_1 x_{i1} + ... + \\hat \\beta_p x_{ip}))^2  + \\lambda_1 \\cdot L_{1, lasso} + \\lambda_2 \\cdot L_{2, ridge} = $  \n",
    "$ = \\sum_{i=1}^{n} (y_i - (\\hat\\beta_0 + \\hat\\beta_1 x_{i1} + ... + \\hat \\beta_p x_{ip}))^2  + \\lambda_1 \\cdot \\underbrace{\\sum_{j=1}^{p} |\\hat \\beta_j|}_{L_{1,lasso}} + \\underbrace{(1-\\lambda_1)}_{\\lambda_2} \\cdot \\underbrace{\\sum_{j=1}^{p} \\hat \\beta_j^2}_{L_{2, ridge}} $  \n",
    "- `glmnet()` referst to the above formula:  \n",
    "so when $\\lambda_1$=1 => lasso, when $\\lambda_1$ = 0 => ridge, when 0 < $\\lambda_1$ < 1 => elastic net. ( `glmnet()` refers to $\\lambda_1$ as `alpha`)    \n",
    "- Elastic Net often outperforms Lasso in terms of prediction accuracy.  \n",
    "- $\\lambda$ gets derived from Cross-Validation: the selected $\\lambda$ yields minimal MSE in SLR/MLR or minimal Sum of Square Deviances in Poisson/Logistic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### R libraries  pertaining to Variable Selection Methods\n",
    "`library(CombMSC)` - Obtain Mallow's Cp, AIC, BIC criterion values for full model and submodel  \n",
    "`library(boot)`- used with `glm()`: 10-fold CV and leave one out CV   \n",
    "`library(leaps)` - stepwise model selection, searches over all possible $2^p$ submodels; cons: fitting all submodels may be impossible, does not have a AIC or BIC implementation, cannot force it to always include certain (controlling) variables in the model   \n",
    "`step(lm())` - stepwise model selection, more flexible: allows AIC and BIC, may specify to always include certain (controlling) variables in the model  \n",
    "- `forward.model = step(minimum, scope = list(lower=minimum, upper = full), direction = \"forward\")`\n",
    "- `backward.model = step(full, scope = list(lower=minimum, upper = full), direction = \"backward\")`  \n",
    "- `both.min.model = step(minimum, scope = list(lower=minimum, upper = full), direction = \"both\")`\n",
    "- `both.full.model = step(full, scope = list(lower=minimum, upper = full), direction = \"both\")`\n",
    "\n",
    "`library(MASS)` - yet another implementation of Ridge  \n",
    "`library(lars)` - yet another implementation of Lasso  \n",
    "`library(glmnet)`- Elastic Net = Lasso + Ridge, Lasso, Ridge, Cross-Validation    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
